{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import matplotlib as mp\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation,TruncatedSVD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading data in dataframe\n",
    "train=pd.read_csv(\"../input/train.csv\",sep=',')\n",
    "test=pd.read_csv(\"../input/test.csv\",sep=',')\n",
    "train_y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1228545.03it/s]\n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1225738.50it/s]\n",
      "100%|██████████| 1306122/1306122 [00:05<00:00, 222097.71it/s]\n",
      "100%|██████████| 1306122/1306122 [00:03<00:00, 407125.90it/s]\n",
      "100%|██████████| 1306122/1306122 [00:03<00:00, 417413.26it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 442215.37it/s]\n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 984290.01it/s] \n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 980635.42it/s] \n",
      "100%|██████████| 1306122/1306122 [00:18<00:00, 72539.00it/s]\n",
      "100%|██████████| 1306122/1306122 [00:03<00:00, 395582.54it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 944515.13it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 1190336.24it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 222542.06it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 405488.97it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 404496.26it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 438829.35it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 958215.29it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 935815.76it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 75866.32it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 390333.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df['question_text'] = df['question_text'].progress_apply(lambda x: str(x))\n",
    "    # 字符串的长度，字母的数量\n",
    "    df['num_chars'] = df['question_text'].progress_apply(len)\n",
    "    # 单词的数量\n",
    "    df['num_words'] = df.question_text.str.count('\\S+')\n",
    "    # 字符串中大写字母的数量https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc\n",
    "    df['num_capital'] = df['question_text'].progress_apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "    # 大写字母数占总字母数的比率\n",
    "    df['capital_rate'] = df['num_capital'] / df['num_chars']\n",
    "    \n",
    "    # 不重复单词的种数\n",
    "    df['num_uniquewords'] = df['question_text'].progress_apply(lambda x: len(set(x.split())))\n",
    "    df['unique_rate'] = df['num_uniquewords'] / df['num_words']\n",
    "    \n",
    "    # istitle()字符串中所有单词首字母大写则为真，也就是统计首字母大写的单次数\n",
    "    df[\"num_titlewords\"] = df[\"question_text\"].progress_apply(lambda x: len([w for w in x.split() if w.istitle()]))\n",
    "    # 词频\n",
    "    df['title_rate'] = df['num_titlewords'] / df['num_words']\n",
    "    \n",
    "    # 字符串中所有字母大写则为真\n",
    "    df[\"num_upperwords\"] = df[\"question_text\"].progress_apply(lambda x: len([w for w in x.split() if w.isupper()]))\n",
    "    df['upper_rate'] = df['num_upperwords'] / df['num_words']\n",
    "    \n",
    "    # 统计“！”的数目\n",
    "    df[\"num_exc\"] = df[\"question_text\"].progress_apply(lambda x: x.count(\"!\")).astype('uint16')\n",
    "    # 统计“？”的数目\n",
    "    df[\"num_q\"] = df['question_text'].progress_apply(lambda x: x.count(\"?\")).astype('uint16')\n",
    "    # 单词长度的平均值\n",
    "    df[\"mean_word_len\"] = df[\"question_text\"].progress_apply(lambda x: np.mean([len(w) for w in x.split()]))\n",
    "    # 单词长度的最大值\n",
    "    df[\"max_word_len\"] = df['question_text'].progress_apply(lambda x: max([len(w) for w in x.split()]))\n",
    "\n",
    "    return df\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = train.columns.tolist()\n",
    "feat_list = [feat for feat in feat_list if feat not in ['qid','question_text','target']]\n",
    "\n",
    "train_x = train[feat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 0:02:01.751828\n"
     ]
    }
   ],
   "source": [
    "begin = datetime.now()\n",
    "tfidf_v = TfidfVectorizer(stop_words='english', ngram_range=(1,3), max_features=90000)\n",
    "matrixTFIDF= tfidf_v.fit_transform(train.question_text)\n",
    "# matrixTFIDF= tfidf_v.fit_transform(train[train.target==1].question_text)\n",
    "\n",
    "svd=TruncatedSVD(n_components=30, n_iter=10,random_state=42)\n",
    "X=svd.fit_transform(matrixTFIDF) \n",
    "print('time used:',datetime.now() - begin)\n",
    "\n",
    "# begin = datetime.now()\n",
    "# lda=LatentDirichletAllocation(n_components=15,random_state=42)\n",
    "# Z=lda.fit_transform(matrixTFIDF)  \n",
    "# print('time used:',datetime.now() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd=TruncatedSVD(n_components=40, n_iter=10,random_state=42)\n",
    "X=svd.fit_transform(matrixTFIDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_best_score(y_true, y_pred):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in [i * 0.01 for i in range(50)]:\n",
    "        score = f1_score(y_true=y_true, y_pred=(y_pred > threshold).astype(int))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    return \"my_score\", best_score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, train_y, test_size=0.2,random_state=2018, stratify=train_y)\n",
    "    clf = lgb.LGBMClassifier(learning_rate=0.05,objective='binary',reg_alpha=0,num_leaves =32,\n",
    "                             subsample=0.8, colsample_bytree=1, n_estimators=2000,\n",
    "                             early_stopping_round=100)\n",
    "    \n",
    "    clf.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_val,y_val)], \n",
    "            verbose=50, eval_metric=['auc'], early_stopping_rounds=100)\n",
    "    pred_val_y = clf.predict_proba(X_val,num_iteration=clf.best_iteration_)[:,1]\n",
    "#     pred_test_y = clf.predict_proba(test_tfidf,num_iteration=clf.best_iteration_)[:,1]\n",
    "\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "\n",
    "    for threshold in [i * 0.01 for i in range(50)]:\n",
    "        score = f1_score(y_val, (pred_val_y>threshold).astype(int))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "            \n",
    "    print('best score:%f,best threshold:%f'%(best_score, best_threshold))\n",
    "    gc.collect()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linxid/anaconda3/envs/python3.6/lib/python3.6/site-packages/lightgbm/engine.py:121: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.875307\tvalid_0's binary_logloss: 0.168805\tvalid_1's auc: 0.870797\tvalid_1's binary_logloss: 0.170171\n",
      "[100]\tvalid_0's auc: 0.887616\tvalid_0's binary_logloss: 0.161096\tvalid_1's auc: 0.881881\tvalid_1's binary_logloss: 0.16322\n",
      "[150]\tvalid_0's auc: 0.894428\tvalid_0's binary_logloss: 0.157291\tvalid_1's auc: 0.887475\tvalid_1's binary_logloss: 0.160137\n",
      "[200]\tvalid_0's auc: 0.899094\tvalid_0's binary_logloss: 0.154771\tvalid_1's auc: 0.890879\tvalid_1's binary_logloss: 0.158303\n",
      "[250]\tvalid_0's auc: 0.902738\tvalid_0's binary_logloss: 0.152901\tvalid_1's auc: 0.892823\tvalid_1's binary_logloss: 0.157254\n",
      "[300]\tvalid_0's auc: 0.90607\tvalid_0's binary_logloss: 0.151276\tvalid_1's auc: 0.894293\tvalid_1's binary_logloss: 0.156478\n",
      "[350]\tvalid_0's auc: 0.908695\tvalid_0's binary_logloss: 0.149925\tvalid_1's auc: 0.895267\tvalid_1's binary_logloss: 0.155957\n",
      "[400]\tvalid_0's auc: 0.911395\tvalid_0's binary_logloss: 0.148562\tvalid_1's auc: 0.896326\tvalid_1's binary_logloss: 0.155388\n",
      "[450]\tvalid_0's auc: 0.91358\tvalid_0's binary_logloss: 0.147397\tvalid_1's auc: 0.897026\tvalid_1's binary_logloss: 0.155006\n",
      "[500]\tvalid_0's auc: 0.915606\tvalid_0's binary_logloss: 0.146236\tvalid_1's auc: 0.89777\tvalid_1's binary_logloss: 0.154587\n",
      "[550]\tvalid_0's auc: 0.917593\tvalid_0's binary_logloss: 0.145141\tvalid_1's auc: 0.898328\tvalid_1's binary_logloss: 0.154273\n",
      "[600]\tvalid_0's auc: 0.919489\tvalid_0's binary_logloss: 0.144054\tvalid_1's auc: 0.898969\tvalid_1's binary_logloss: 0.153911\n",
      "[650]\tvalid_0's auc: 0.921237\tvalid_0's binary_logloss: 0.143063\tvalid_1's auc: 0.899393\tvalid_1's binary_logloss: 0.153667\n",
      "[700]\tvalid_0's auc: 0.922925\tvalid_0's binary_logloss: 0.142116\tvalid_1's auc: 0.899814\tvalid_1's binary_logloss: 0.153427\n",
      "[750]\tvalid_0's auc: 0.924504\tvalid_0's binary_logloss: 0.141201\tvalid_1's auc: 0.900096\tvalid_1's binary_logloss: 0.153249\n",
      "[800]\tvalid_0's auc: 0.926116\tvalid_0's binary_logloss: 0.140284\tvalid_1's auc: 0.900441\tvalid_1's binary_logloss: 0.153056\n",
      "[850]\tvalid_0's auc: 0.927738\tvalid_0's binary_logloss: 0.139367\tvalid_1's auc: 0.900835\tvalid_1's binary_logloss: 0.152863\n",
      "[900]\tvalid_0's auc: 0.929217\tvalid_0's binary_logloss: 0.138487\tvalid_1's auc: 0.901126\tvalid_1's binary_logloss: 0.152688\n",
      "[950]\tvalid_0's auc: 0.93073\tvalid_0's binary_logloss: 0.1376\tvalid_1's auc: 0.901448\tvalid_1's binary_logloss: 0.152502\n",
      "[1000]\tvalid_0's auc: 0.931925\tvalid_0's binary_logloss: 0.136818\tvalid_1's auc: 0.901695\tvalid_1's binary_logloss: 0.152351\n",
      "[1050]\tvalid_0's auc: 0.93326\tvalid_0's binary_logloss: 0.13598\tvalid_1's auc: 0.901942\tvalid_1's binary_logloss: 0.152193\n",
      "[1100]\tvalid_0's auc: 0.934547\tvalid_0's binary_logloss: 0.135178\tvalid_1's auc: 0.902196\tvalid_1's binary_logloss: 0.152051\n",
      "[1150]\tvalid_0's auc: 0.93567\tvalid_0's binary_logloss: 0.134403\tvalid_1's auc: 0.902465\tvalid_1's binary_logloss: 0.151893\n",
      "[1200]\tvalid_0's auc: 0.936771\tvalid_0's binary_logloss: 0.13367\tvalid_1's auc: 0.902662\tvalid_1's binary_logloss: 0.151779\n",
      "[1250]\tvalid_0's auc: 0.93768\tvalid_0's binary_logloss: 0.133007\tvalid_1's auc: 0.902823\tvalid_1's binary_logloss: 0.151682\n",
      "[1300]\tvalid_0's auc: 0.938746\tvalid_0's binary_logloss: 0.1323\tvalid_1's auc: 0.902974\tvalid_1's binary_logloss: 0.151585\n",
      "[1350]\tvalid_0's auc: 0.939876\tvalid_0's binary_logloss: 0.131568\tvalid_1's auc: 0.903142\tvalid_1's binary_logloss: 0.151482\n",
      "[1400]\tvalid_0's auc: 0.940871\tvalid_0's binary_logloss: 0.130909\tvalid_1's auc: 0.903236\tvalid_1's binary_logloss: 0.151415\n",
      "[1450]\tvalid_0's auc: 0.941916\tvalid_0's binary_logloss: 0.130191\tvalid_1's auc: 0.903467\tvalid_1's binary_logloss: 0.151287\n",
      "[1500]\tvalid_0's auc: 0.943134\tvalid_0's binary_logloss: 0.12945\tvalid_1's auc: 0.903581\tvalid_1's binary_logloss: 0.151211\n",
      "[1550]\tvalid_0's auc: 0.943993\tvalid_0's binary_logloss: 0.128824\tvalid_1's auc: 0.903686\tvalid_1's binary_logloss: 0.151135\n",
      "[1600]\tvalid_0's auc: 0.944953\tvalid_0's binary_logloss: 0.128168\tvalid_1's auc: 0.903821\tvalid_1's binary_logloss: 0.151061\n",
      "[1650]\tvalid_0's auc: 0.945891\tvalid_0's binary_logloss: 0.127515\tvalid_1's auc: 0.903941\tvalid_1's binary_logloss: 0.150978\n",
      "[1700]\tvalid_0's auc: 0.946776\tvalid_0's binary_logloss: 0.126887\tvalid_1's auc: 0.904092\tvalid_1's binary_logloss: 0.150908\n",
      "[1750]\tvalid_0's auc: 0.947677\tvalid_0's binary_logloss: 0.126255\tvalid_1's auc: 0.904206\tvalid_1's binary_logloss: 0.15083\n",
      "[1800]\tvalid_0's auc: 0.948525\tvalid_0's binary_logloss: 0.12566\tvalid_1's auc: 0.904272\tvalid_1's binary_logloss: 0.15079\n",
      "[1850]\tvalid_0's auc: 0.949207\tvalid_0's binary_logloss: 0.125107\tvalid_1's auc: 0.904302\tvalid_1's binary_logloss: 0.15076\n",
      "[1900]\tvalid_0's auc: 0.950082\tvalid_0's binary_logloss: 0.124488\tvalid_1's auc: 0.904394\tvalid_1's binary_logloss: 0.150714\n",
      "[1950]\tvalid_0's auc: 0.950983\tvalid_0's binary_logloss: 0.123853\tvalid_1's auc: 0.904466\tvalid_1's binary_logloss: 0.150665\n",
      "[2000]\tvalid_0's auc: 0.951655\tvalid_0's binary_logloss: 0.123307\tvalid_1's auc: 0.904522\tvalid_1's binary_logloss: 0.150634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's auc: 0.951655\tvalid_0's binary_logloss: 0.123307\tvalid_1's auc: 0.904522\tvalid_1's binary_logloss: 0.150634\n",
      "best score:0.489398,best threshold:0.240000\n"
     ]
    }
   ],
   "source": [
    "train_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
