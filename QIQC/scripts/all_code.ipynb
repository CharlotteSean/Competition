{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Insincere Questions Classification\n",
    "> Detect toxic content to improve online conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import operator \n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from collections import Counter, OrderedDict\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.models import *\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.regularizers import *\n",
    "from keras import backend as K\n",
    "from keras.legacy import interfaces\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')\n",
    "sub = pd.read_csv(\"../input/submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "[ref: 如何在 Keras 开发过程中获取可复现的结果？](https://keras.io/zh/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development)\n",
    "\n",
    "[ref: How can I obtain reproducible results using Keras during development?](https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2018\n",
    "# python\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "# random\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "# tf\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "# data\n",
    "max_features = 95000\n",
    "maxlen = 72\n",
    "cv = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1306122, 3)\n",
      "Test shape:  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Train shape: \", train.shape)\n",
    "print(\"Test shape: \", test.shape)\n",
    "sub = test[['qid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 数据采样\n",
    "# train_pos = train[train['target']==1]\n",
    "# print(\"train_pos shape: \", train_pos.shape)\n",
    "# train_neg = train[train['target']==0]\n",
    "# print(\"train_neg shape: \", train_neg.shape)\n",
    "# train_neg = train_neg.sample(frac=0.2)\n",
    "# print(\"train_neg shape: \", train_neg.shape)\n",
    "# train = pd.concat([train_pos, train_neg])\n",
    "# train = train.sample(frac=1)\n",
    "# print(\"Train shape: \", train.shape)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emb(filename):\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    if \"wiki-news-300d-1M.vec\" in filename:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(filename) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(filename, encoding='latin'))\n",
    "    return embeddings_index\n",
    "\n",
    "glove = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "para = \"../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\"\n",
    "# fasttext = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "print(\"Extracting embedding\")\n",
    "embeddings_index_glove = load_emb(glove)\n",
    "embeddings_index_para = load_emb(para)\n",
    "# embeddings_index_fasttext = load_emb(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有词\n",
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "    # 词向量中有的词占总词的种数的比例（比较种类）\n",
    "    print('Found embeddings for {:.3%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    # 整个文本中，知道词的数目占总次数的比例（比较数目）\n",
    "    print('Found embeddings for  {:.3%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "    return unknown_words\n",
    "\n",
    "\n",
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(f\"Added {count} words to embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get set of all punctuations in dataset\n",
    "tmp = []\n",
    "for x in train.question_text:\n",
    "    for c in x:\n",
    "        if not c.isalnum():\n",
    "            tmp.append(c)\n",
    "for x in test.question_text:\n",
    "    for c in x:\n",
    "        if not c.isalnum():\n",
    "            tmp.append(c)\n",
    "puncs = set(tmp) - set(' ')\n",
    "unpunc = puncs - set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction = { \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\",\n",
    "                \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
    "                \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\",\n",
    "                \"haven't\": \"have not\", \"haven ' t\"\"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "                \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"i'll've\": \"i will have\",\n",
    "                \"i'm\": \"i am\", \"i've\": \"i have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "                \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\",\n",
    "                \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n",
    "                \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "                \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\",\n",
    "                \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
    "                \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
    "                \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
    "                \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "                \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
    "                \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\",\n",
    "                \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "                \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\",\n",
    "                \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "                \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\",\n",
    "                \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
    "                \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
    "                \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "punc = {\"ँ\": \"\", \"◦\": \"\", \"̆\": \"\", \"✏\": \"\", \"\": \"\", \"ี\": \"\", \"♡\": \"o\", \"△\": \"\", \"⇒\": \"\", \"\u0006\": \"\", \"＄\": \" dollar \",\n",
    "        \"→\": \"\", \"͚\": \"\", \"️\": \"\", \"⟩\": \"\", \"¡\": \"i\", \"್\": \"\", \"‬\": \"\", \"̘\": \"\", \"ា\": \"\", \"¿\": \"?\", \"⧼\": \"\",\n",
    "        \"\u0002\": \"\", \"®\": \" r \", \"ौ\": \"\", \"∼\": \"\", \"َ\": \"\", \"ూ\": \"\", \"”\": \"'\", \"̙\": \"\", \"⋅\": \"\", \"̷\": \"\", \"̓\": \"\", \"、\": \"\",\n",
    "        \"⬇\": \"\", \"̔\": \"\", \"∗\": \"*\", \"͕\": \"\", \"͡\": \"\", \"̿\": \"\", \"‌\": \"\", \"͜\": \"\", \"̦\": \"\", \"\": \"\", \"♨\": \"\", \"̮\": \"\",\n",
    "        \"ௌ\": \"\", \"»\": \" \", \"➡\": \"\", \"̼\": \"\", \"̌\": \"\", \"̢\": \"\", \"？\": \"?\", \"\u0010\": \"\", \"ৃ\": \"\", \"ం\": \"\", \"⊥\": \"\",\n",
    "        \"̧\": \"\", \"ਾ\": \"\", \"》\": \" \", \"ਂ\": \"\", \"ិ\": \"\", \"∨\": \"\", \"ী\": \"\", \"े\": \"\", \"⧽\": \"\", \"⁡\": \"\", \"ु\": \"\",\n",
    "        \"ٌ\": \"\", \"₦\": \" naira \", \"̸\": \"\", \"़\": \"\", \"̃\": \"\", \"\u0017\": \"\", \"͎\": \"\", \"∧\": \"\", \"，\": \"\", \"÷\": \"/\", \"،\": \"\",\n",
    "        \"↓\": \"\", \"✔\": \"\", \"⁠\": \"\", \"¶\": \"\", \"ೋ\": \"\", \"͖\": \"\", \"ে\": \"\", \"☝\": \"\", \"«\": \" \", \"\u0001\": \"\", \"ं\": \"\",\n",
    "        \"《\": \" \", \"ॉ\": \"\", \"）\": \"\", \"͉\": \"\", \"⟨\": \"\", \"\": \"\", \"ْ\": \"\", \"‏\": \"\", \"₱\": \" peso \", \"°\": \"\",\n",
    "        \"͋\": \"\", \"✌\": \"\", \"্\": \"\", \"᠌\": \"\", \"♣\": \"\", \"×\": \"x\", \"ো\": \"\", \"؟\": \"?\", \"˜\": \"\", \"̩\": \"\", \"̱\": \"\",\n",
    "        \"̺\": \"\", \"͔\": \"\", \"▾\": \"\", \"⎛\": \"\", \"ొ\": \"\", \"்\": \"\", \"̊\": \"\", \"̥\": \"\", \"ੁ\": \"\", \"่\": \"\", \"﻿\": \"\", \"˚\": \"\",\n",
    "        \"ా\": \"\", \"ા\": \"\", \"™\": \" tm \", \"ِ\": \"\", \"∈\": \"\", \"⃗\": \"\", \"≅\": \"=\", \"̵\": \"\", \"♭\": \"\", \"ಾ\": \"\", \"；\": \".\",\n",
    "        \"̒\": \"\", \"ி\": \"\", \"´\": \"'\", \"＞\": \">\", \"̣\": \"\", \"ุ\": \"\", \"ّ\": \"\", \"▒\": \"\", \"।\": \"\", \"–\": \"-\", \"∖\": \"\",\n",
    "        \"̰\": \"\", \"ॄ\": \"\", \"‘\": \"'\", \"̶\": \"-\", \"ो\": \"\", \"！\": \"!\", \"☺\": \"\", \"̎\": \"\", \"″\": \"\", \"＝\": \"=\", \"˂\": \"\",\n",
    "        \"਼\": \"\", \"ः\": \"\", \"ֿ\": \"\", \"♏\": \"\", \"¦\": \"\", \"̝\": \"\", \"̈\": \"\", \"́\": \"\", \"‐\": \"-\", \"“\": \"'\", \"ാ\": \"\",\n",
    "        \"≤\": \"<=\", \"ੀ\": \"\", \"\u001b\": \"\", \"\\n\": \"\", \"◌\": \"\", \"ृ\": \"\", \"ு\": \"\", \"ा\": \"\", \"¥\": \" yen \", \"‑\": \"-\",\n",
    "        \"￼\": \"\", \"\u0013\": \"\", \"्\": \"\", \"̭\": \"\", \"\": \"\", \"¬\": \"\", \"͌\": \"\", \"̍\": \"\", \"„\": \"\", \"ី\": \"\", \"•\": \"\", \"↑\": \"\",\n",
    "        \"͘\": \"\", \"\": \"\", \"͇\": \"\", \"̫\": \"\", \"ா\": \"\", \"͛\": \"\", \"︠\": \"\", \"⁻\": \"-\", \"᾽\": \"\", \"ি\": \"\", \"̟\": \"\", \"│\": \"|\",\n",
    "        \"̕\": \"\", \"͊\": \"\", \"̑\": \"\", \"‎\": \"\", \"☁\": \"\", \"ಿ\": \"\", \"ी\": \"\", \"̀\": \"\", \"়\": \"\", \"̐\": \"\", \"☉\": \"\", \"\u001a\": \"\",\n",
    "        \"⚧\": \"\", \"£\": \" pound \", \"・\": \"\", \"⋯\": \"...\", \"−\": \"-\", \"∅\": \" \", \"¸\": \",\", \"̋\": \"\", \"̲\": \"\", \"⎝\": \"\",\n",
    "        \"͆\": \"\", \"〗\": \"]\", \"／\": \"\", \"ั\": \"\", \"：\": \"\", \"ோ\": \"\", \"̽\": \"\", \"©\": \" c \", \"\": \"\", \"്\": \"\", \"ು\": \"\",\n",
    "        \"ు\": \"\", \"్\": \"\", \"ि\": \"\", \"⊨\": \"\", \"̈́\": \"\", \"̚\": \"\", \"̖\": \"\", \"̡\": \"\", \"·\": \".\", \"✅\": \"\", \"ͅ\": \"\",\n",
    "        \"ੰ\": \"\", \"̾\": \"\", \"…\": \"\", \"＾\": \"^\", \"≈\": \"=\", \"—\": \"-\", \"♀\": \"\", \"❤\": \"\", \"્\": \"\", \"ା\": \"\", \"¢\": \"\",\n",
    "        \"⎞\": \"\", \"ె\": \"\", \"​\": \"\", \"̻\": \"\", \"（\": \"\", \"‪\": \"\", \"≠\": \"!=\", \"ॢ\": \"\", \"ં\": \"\", \"〖\": \"[\", \"­\": \"\", \"∂\": \"\",\n",
    "        \"̬\": \"\", \"͐\": \"\", \"\": \"\", \"₊\": \"+\", \"℅\": \"%\", \"̛\": \"\", \"‰\": \"\", \"ਿ\": \"\", \"͈\": \"\", \"́\": \"\", \"͂\": \"\", \"̞\": \"\",\n",
    "        \"ి\": \"\", \"้\": \"\", \"̗\": \"\", \"ു\": \"\", \"\u0003\": \"\", \"’\": \"'\", \"া\": \"\", \"ើ\": \"\", \"\": \"\", \"ះ\": \"\", \"」\": \"]\", \"︡\": \"\",\n",
    "        \"ू\": \"\", \"̳\": \"\", \"ை\": \"\", \"⊂\": \"\", \"∇\": \"\", \"≥\": \">=\", \"̄\": \"\", \"₹\": \" e \", \"̜\": \"\", \"̴\": \"\", \"℃\": \"\",\n",
    "        \"±\": \"+\", \"⌚\": \" time \", \"≡\": \"\", \"̹\": \"\", \"̯\": \"\", \"′\": \"\", \"ీ\": \"\", \"ូ\": \"\", \"－\": \" \", \"「\": \"[\", \"̀\": \"\",\n",
    "        \"¨\": \"'\", \"ॣ\": \"\", \"⦁\": \"\", \"€\": \" euro \", \"❓\": \"?\", \"ู\": \"\", \"͗\": \"\", \"̅\": \"\", \"̂\": \"\", \"͠\": \"\", \"̤\": \"\",\n",
    "        \"្\": \"\", \"̉\": \"\", \"₩\": \"\", \"\": \"\", \"̪\": \"\", \"ै\": \"\", \"∘\": \"\", \"ៃ\": \"\", \"͑\": \"\", \"ំ\": \"\", \"͒\": \"\", \"☹\": \"\",\n",
    "        \"͝\": \"\", \"‛\": \"'\", \"⎠\": \"\", \"¯\": \"\", \"。\": \".\", \"∆\": \"\", \"ി\": \"\", \"̓\": \"\", \"∝\": \"\", \"†\": \"\", \"≱\": \"\", \"²\": \"2\",\n",
    "        \"`\": \"'\", 'à': 'a', '³': '3', 'π': 'pi', \"₁\": \"1\", \"₃\": \"3\", \"₆\": \"6\", \"¼\": \"1/4\", \"⁷\": \"7\", \"¾\": \"3/4\",\n",
    "        \"⁵\": \"5\", \"₅\": \"5\", \"½\": \"1/2\", \"₄\": \"4\", \"⅔\": \"2/3\", \"₂\": \"2\", \"¹\": \"1\"}\n",
    "\n",
    "mispell = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling',\n",
    "           'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor',\n",
    "           'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu': 'youtube ',\n",
    "           'qoura': 'quora', 'quorans': 'quora users', 'quoran': 'quora user', 'sallary': 'salary', 'whta': 'what',\n",
    "           'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much',\n",
    "           'howmany': 'how many', 'whydo': 'why do', 'doi': 'do i', 'thebest': 'the best', 'howdoes': 'how does',\n",
    "           'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating',\n",
    "           'pennis': 'penis', 'etherium': 'ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data',\n",
    "           '2k15': '2015', '2k16': '2016', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend',\n",
    "           'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization',\n",
    "           'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokémon': 'pokemon',\n",
    "           'nanodegree': 'nano degree', 'brexit': 'british exit', 'cryptocurrencies': 'crypto currencies',\n",
    "           'coinbase': 'coin base', 'oneplus': 'one plus', 'redmi': 'red mi', 'GDPR': 'general data protection regulation',\n",
    "           'DCEU': 'dc extended universe', 'litecoin': 'lite coin', 'unacademy': 'non academy', 'altcoin': 'bitcoin alternative',\n",
    "           'altcoins': 'bitcoin alternative', 'sjw': 'social justice warriors', 'sjws': 'social justice warriors',\n",
    "           'fiancé': 'fiance', 'microservices': 'micro services', 'bitconnect': 'bit connect', 'codeforces': 'code forces',\n",
    "           'wannacry': 'wanna cry', 'onedrive': 'one drive', 'airpods': 'air pods', 'twinflame': 'twin flame',\n",
    "           'undergraduation': 'under graduation', 'cos2x': 'cos 2 x', 'yourquote': 'your quote', 'xiomi': 'xiaomi',\n",
    "           'undertale': 'under tale', 'genderfluid': 'gender fluid', 'são': 'sao', 'chapterwise': 'chapter wise',\n",
    "           'deepmind': 'deep mind', '': '', 'arrowverse': 'arrow verse', 'overbrace': ' ', 'tensorflow': 'tensor flow',\n",
    "           'hackerrank': 'hacker rank', 'microservice': 'micro service', 'reactjs': 'react js', 'hackerearth': 'hacker earth',\n",
    "           'fiancée': 'fiance', 'blockchains': 'block chains', 'beyoncé': 'beyonce', 'neuralink': 'neura link',\n",
    "           'openai': 'open ai', 'zoomcar': 'zoom car', 'hyperconjugation': 'hyper conjugation', 'autoencoder': 'auto encoder',\n",
    "           'webassembly': 'web assembly', 'quoras': 'quora', 'digilocker': 'digi locker', 'oversmart': 'over smart',\n",
    "           'cryptocoins': 'crypto coins', 'crytocurrencies': 'cryto currencies', 'cyrptocurrency': 'cyrpto currency',\n",
    "           'café': 'cafe', 'whatapp': 'whatsapp', 'gaslighter': 'gas lighter', 'darkweb': 'dark web', 'webnovel': 'web novel'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_quote(text):\n",
    "    quote = ['´', '‘', '’', \"`\"]\n",
    "    for s in quote:\n",
    "        text = text.replace(s, \"'\")\n",
    "    return text\n",
    "                      \n",
    "def re_mapping(mapping):\n",
    "    res = re.compile('(%s)' % '|'.join(mapping.keys()))\n",
    "    return res\n",
    "\n",
    "mapping = dict(set(contraction.items()) | set(mispell.items()))\n",
    "re_map = re_mapping(mapping)\n",
    "def replace_mapping(text):\n",
    "    def replace(match):\n",
    "        return mapping[match.group(0)]\n",
    "    return re_map.sub(replace, text)\n",
    "\n",
    "re_punc = re_mapping(punc)\n",
    "def replace_punc(text):\n",
    "    def replace(match):\n",
    "        return punc[match.group(0)]\n",
    "    return re_punc.sub(replace, text)\n",
    "\n",
    "def sep_punc(x):\n",
    "    for p in puncs:\n",
    "        x = x.replace(p, f' {p} ')\n",
    "    return x\n",
    "\n",
    "def replace_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def add_features(df):\n",
    "    df['question_text'] = df['question_text'].progress_apply(lambda x: str(x))\n",
    "    df['num_chars'] = df['question_text'].progress_apply(len)\n",
    "    df['num_words'] = df.question_text.str.count('\\S+')\n",
    "\n",
    "    df['num_capital'] = df['question_text'].progress_apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "    df['capital_rate'] = df['num_capital'] / df['num_words']\n",
    "\n",
    "    df['num_uniquewords'] = df['question_text'].progress_apply(lambda x: len(set(x.split())))\n",
    "    df['unique_rate'] = df['num_uniquewords'] / df['num_words']\n",
    "\n",
    "    df[\"num_titlewords\"] = df[\"question_text\"].progress_apply(lambda x: len([w for w in x.split() if w.istitle()]))\n",
    "    df['title_rate'] = df['num_titlewords'] / df['num_words']\n",
    "    \n",
    "    df[\"num_upperwords\"] = df[\"question_text\"].progress_apply(lambda x: len([w for w in x.split() if w.isupper()]))\n",
    "    df['upper_rate'] = df['num_upperwords'] / df['num_words']\n",
    "    \n",
    "    df[\"num_exc\"] = df[\"question_text\"].progress_apply(lambda x: x.count(\"!\")).astype('uint16')\n",
    "    df[\"num_q\"] = df['question_text'].progress_apply(lambda x: x.count(\"?\")).astype('uint16')\n",
    "    df[\"num_,\"] = df['question_text'].progress_apply(lambda x: x.count(\",\")).astype('uint16')\n",
    "    df[\"num_.\"] = df['question_text'].progress_apply(lambda x: x.count(\".\")).astype('uint16')\n",
    "    df[\"mean_word_len\"] = df[\"question_text\"].progress_apply(lambda x: np.mean([len(w) for w in x.split()]))\n",
    "    df[\"max_word_len\"] = df['question_text'].progress_apply(lambda x: max([len(w) for w in x.split()]))\n",
    "\n",
    "    df[\"num_unpunc\"] = df[\"question_text\"].progress_apply(lambda x: sum(x.count(p) for p in unpunc)).astype('uint16')\n",
    "    df[\"num_punc\"] = df[\"question_text\"].progress_apply(lambda x: sum(x.count(p) for p in punctuation)).astype('uint16')\n",
    "    df[\"num_mispell\"] = df[\"question_text\"].progress_apply(lambda x: sum(x.count(p) for p in mispell)).astype('uint16')\n",
    "    \n",
    "#     for s in [\",\", \";\", '\"', \"...\", \"?\", \"!\", \".\", \":\", \"*\", \"-\"]:\n",
    "#         df[s] = df[\"question_text\"].progress_apply(lambda x: np.mean([len(w) for w in x.split(s)]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1294245.98it/s]\n",
      "100%|██████████| 1306122/1306122 [00:00<00:00, 1363556.60it/s]\n",
      "100%|██████████| 1306122/1306122 [00:05<00:00, 219464.58it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 439676.27it/s]\n",
      "100%|██████████| 1306122/1306122 [00:03<00:00, 429827.37it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 472993.50it/s]\n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1073922.44it/s]\n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1106692.92it/s]\n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1098404.29it/s]\n",
      "100%|██████████| 1306122/1306122 [00:01<00:00, 1103008.75it/s]\n",
      "100%|██████████| 1306122/1306122 [00:12<00:00, 102693.65it/s]\n",
      "100%|██████████| 1306122/1306122 [00:03<00:00, 435253.45it/s]\n",
      "100%|██████████| 1306122/1306122 [01:05<00:00, 19958.70it/s]\n",
      "100%|██████████| 1306122/1306122 [00:07<00:00, 172517.81it/s]\n",
      "100%|██████████| 1306122/1306122 [00:26<00:00, 49469.87it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 1229180.75it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 1307950.15it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 222172.55it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 437044.77it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 439611.02it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 465291.81it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 970674.11it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 1022744.31it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 1047247.67it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 1024237.42it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 102189.56it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 413037.37it/s]\n",
      "100%|██████████| 56370/56370 [00:02<00:00, 19891.90it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 167859.83it/s]\n",
      "100%|██████████| 56370/56370 [00:01<00:00, 49171.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add features done\n"
     ]
    }
   ],
   "source": [
    "# 0.689\n",
    "# feature_cols = ['capital_rate', 'unique_rate', 'title_rate', 'upper_rate']\n",
    "\n",
    "# 0.694\n",
    "# feature_cols = ['num_chars', 'num_words', 'num_capital', 'num_uniquewords', \"num_titlewords\", \"num_upperwords\",\n",
    "#                 \"num_exc\", \"num_q\", \"mean_word_len\", \"max_word_len\", \"num_unpunc\", \"num_punc\", \"num_mispell\"]\n",
    "# feature_cols += [\",\", \";\", '\"', \"...\", \"?\", \"!\", \".\", \":\", \"*\", \"-\"]\n",
    "\n",
    "# 0.697\n",
    "# feature_cols = ['num_chars', 'num_words', 'num_capital', 'num_uniquewords', \"num_titlewords\",\n",
    "#                 \"num_upperwords\", \"num_exc\", \"num_q\", \"mean_word_len\", \"max_word_len\"]\n",
    "\n",
    "# 0.698\n",
    "# feature_cols = [\"num_exc\", \"num_q\", \"mean_word_len\", \"max_word_len\"]\n",
    "\n",
    "# 0.699\n",
    "# feature_cols = ['capital_rate', 'num_chars', 'num_words', \"max_word_len\", \"mean_word_len\",\n",
    "#                 'num_capital', \"num_punc\", 'num_uniquewords', \"num_q\", \"num_unpunc\"]\n",
    "\n",
    "# 0.697\n",
    "# feature_cols = ['capital_rate', 'unique_rate', 'num_chars', 'num_words', \"max_word_len\", \"mean_word_len\",\n",
    "#                 'num_capital', \"num_punc\", 'num_uniquewords', \"num_q\", \"num_unpunc\", \"num_exc\", \"num_mispell\"]\n",
    "\n",
    "# 0.697\n",
    "# feature_cols = ['capital_rate',  'num_chars', 'num_words', \"max_word_len\", \"mean_word_len\", 'num_capital',\n",
    "#                 \"num_punc\", 'num_uniquewords', \"num_q\", \"num_unpunc\", \"num_exc\", \"num_mispell\"]\n",
    "\n",
    "# 0.701\n",
    "feature_cols = ['capital_rate',  'num_chars', 'num_words', \"max_word_len\", \"mean_word_len\",\n",
    "                'num_capital', \"num_punc\", 'num_uniquewords', \"num_q\", \"num_unpunc\", \"num_exc\"]\n",
    "\n",
    "# Add features\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "features = train[feature_cols].fillna(0)\n",
    "test_features = test[feature_cols].fillna(0)\n",
    "ss = StandardScaler()\n",
    "ss.fit(np.vstack((features, test_features)))\n",
    "features = ss.transform(features)\n",
    "test_features = ss.transform(test_features)\n",
    "print(\"Add features done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How did Quebec nationalists see their province as a nation in the 1960s?',\n",
       " 'Do you have an adopted dog, how would you encourage people to adopt and not shop?',\n",
       " 'Why does velocity affect time? Does velocity affect space geometry?',\n",
       " 'How did Otto von Guericke used the Magdeburg hemispheres?',\n",
       " 'Can I convert montra helicon D to a mountain bike by just changing the tyres?',\n",
       " 'Is Gaza slowly becoming Auschwitz, Dachau or Treblinka for Palestinians?',\n",
       " 'Why does Quora automatically ban conservative opinions when reported, but does not do the same for liberal views?',\n",
       " 'Is it crazy if I wash or wipe my groceries off? Germs are everywhere.',\n",
       " 'Is there such a thing as dressing moderately, and if so, how is that different than dressing modestly?',\n",
       " 'Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved, completely disregarding their feelings/lives so you get to have something go your way and feel temporarily at ease. How did things change?',\n",
       " 'What can you say about feminism?',\n",
       " 'How were the Calgary Flames founded?',\n",
       " 'What is the dumbest, yet possibly true explanation for Trump being elected?',\n",
       " 'Can we use our external hard disk as a OS as well as for data storage.will the data be affected?',\n",
       " 'I am 30, living at home and have no boyfriend. I would love a boyfriend and my own home. How can I progress my situation?',\n",
       " 'What do you know about Bram Fischer and the Rivonia Trial?',\n",
       " 'How difficult is it to find a good instructor to take a class near you?',\n",
       " 'Have you licked the skin of a corpse?',\n",
       " 'Do you think Amazon will adopt an in house approach to manufacturing similar to the Tesla or Space X business models?',\n",
       " 'How many baronies might exist within a county palatine?',\n",
       " 'How I know whether a girl had done sex before sex with me?',\n",
       " 'How do I become a fast learner both in my professional career and in my personal life?',\n",
       " 'Has the United States become the largest dictatorship in the world?',\n",
       " 'What is the strangest phenomenon you know of, have witnessed or have generated in the area of electronics that has no explanation in terms of modern physics?',\n",
       " 'Should I leave my friends and find new ones?',\n",
       " 'Can you make Amazon Alexa trigger events in the browser?',\n",
       " \"Why haven't two democracies never ever went for a full fledged war? What stops them?\",\n",
       " 'How can I top CBSE in 6 months?',\n",
       " 'What should I know before visiting Mcleodganj and doing the Triund trek?',\n",
       " 'How do modern military submarines reduce noise to achieve stealth?',\n",
       " 'Which babies are more sweeter to their parents? Dark skin babies or light skin babies?',\n",
       " 'How can I remove black heads which are all over my nose?',\n",
       " 'If lightsabers are created by individual wielders, does each saber have unique powers/abilities?',\n",
       " 'Is anyone still using Visual Basic? Is it worth learning in 2018? Would there be professional jobs for Visual Basic programmers in 2018-19-20?',\n",
       " 'What is Sykes Enterprises all about?',\n",
       " 'Is there any clear relations between the number of nodes/DOFs and the computational performances and requirements in FEA or CFD analyses (for ANSYS solutions in particular)?',\n",
       " \"Why my package still is ISC since May 31,2017 and I don't have updated?\",\n",
       " 'What does great wit mean?',\n",
       " 'In your experience working with Realtors, what do you wish Realtors did better?',\n",
       " 'How do I get charge by contact?',\n",
       " 'Do all public school teachers automatically get vacation whenever they ask for it?',\n",
       " 'What is the role of technology in using a resource?',\n",
       " 'Should I opt Jaypee University Guna for mechanical engineering?',\n",
       " 'Where can I download Microsoft Word for Windows 2.0 in Hungarian?',\n",
       " 'What do I need to know about buying a car in South Africa as an American?',\n",
       " \"As someone who didn't enjoy Harry Potter and the Order of the Phoenix movie, can I at least enjoy the book of it?\",\n",
       " 'What is the writing style of the book \"How to Resist Prince Charming\" by Linda Kage?',\n",
       " 'My mother expects me to memorize all her usernames and passwords. How can I make her more responsible about them as I will be going to college in one year?',\n",
       " 'What is that movie in which a kid is fooled into thinking that germs will kill him and so he lives in a bubble for most of his life, but then decides to travel the world in a portable germ-free bubble?',\n",
       " 'Why most of the computer science student buy final year project from outside rather doing it by own, is our education system really that week?',\n",
       " 'What are some ways to shorten your period, and what are the risks of doing it?',\n",
       " 'Why do we calead leap year.?',\n",
       " 'How many days will it take to get rid of spleen enlargement?',\n",
       " 'Which machine learning techniques can be used to extract metadata (font color, size, indentation and alignment) of a word document (.docx) file, and can it be integrated with a web application?',\n",
       " 'Does it work with girls the way Hitch Will Smith asks not to dance too much?',\n",
       " 'Why India Act 1935 was so special?',\n",
       " \"Are there any sports that you don't like?\",\n",
       " 'How do DNA and RNA compare and contrast?',\n",
       " 'Someone breaks into your house you shoot and kill them they were armed with only a knife what happens now?',\n",
       " 'How can I write a biography about Gianni Versace?',\n",
       " 'Are extroverted better and faster at processing and expelling information than introverts?',\n",
       " 'Have you ever been recognized at a place very far from your home?',\n",
       " 'Why do price comparison websites work well in financial services?',\n",
       " 'Does ragging happen at NIFT Bangalore?',\n",
       " 'Why their are so many bad reviews of Bahubali 2 on IMDb?',\n",
       " 'Is swallowing Listerine dangerous?',\n",
       " 'What are the theories in critical thinking?',\n",
       " 'What are the biggest problems, questions, doubts that you come across when trying to choose the paint color for a room?',\n",
       " 'How can I get cheap flights in Edinburgh?',\n",
       " \"What is China's new chick?\",\n",
       " 'How do I send large picture files through an email?',\n",
       " \"Why doesn't eBay allow the sale of WWII purple heart medals even though they have categories specifically for WWII military medals?\",\n",
       " 'What are the characteristics that define isovolumetric relaxation?',\n",
       " 'How do I work in cybersecurity overseas?',\n",
       " 'Do web developer refer to W3C standard practice?',\n",
       " 'Why has the internet become a problem? Why do we rely on it for everything?',\n",
       " 'Can we get ITC on charges levied by banks?',\n",
       " 'Where is Muhammed now?',\n",
       " 'What are the services that can be provided by a food testing lab and what are their certified requirements?',\n",
       " 'Is it ok to be solo your whole life and pretend no one exists? Is there such thing as being unwanted?',\n",
       " 'How do I change the owner of a current YouTube account? The original Owner was let go and I do not have access to change anything.',\n",
       " 'Are the Archer characters animated based on celebrities?',\n",
       " 'What is the best way to propose a girl without annoying her?',\n",
       " 'What can $500 million get you in solar power?',\n",
       " 'What are the recommended 2D game engines for a beginning Python programmer?',\n",
       " 'Is there such a thing as teleological pantheism?',\n",
       " 'What are some best college for aircraft propulsion(M.S)?',\n",
       " 'What countries in the world have freedom of speech on par with the US?',\n",
       " 'What lead to the Red Terror in Ethiopia?',\n",
       " 'What is the best pen at low cost in all sorts of things?',\n",
       " 'Do you trust a business that has a Facebook page as its website?',\n",
       " 'Should we improve our piano skill by keep practicing hard pieces? Is that the most effective way?',\n",
       " \"I wear an insulin pump, and a lot of girls don't like it. Nick Jonas wears one and dated Selena Gomez. Is there difference between me and Nick several zeros missing in my bank account?\",\n",
       " 'Will Turkey be seperated and give a land to Kurds because of foreign powers like USA in the future?',\n",
       " 'R sq. cos-1 when r=18.5 equals?',\n",
       " 'Who sings the song in my head?',\n",
       " 'Can Chronicled replace supply Chain?',\n",
       " 'How can you solve this equation… Sin(a*t)-b*t=0?',\n",
       " 'What are the demerits of excellence in academic pursuits?',\n",
       " 'How many Indians are in Melbourne, Australia?',\n",
       " \"What do physicists, mathematicians, computer scientists and philosophers think of David Deutsch's 'Constructor Theory'?\",\n",
       " 'Why are old scriptures from eastern cultures appear lost in the current culture?',\n",
       " 'Can I know my I.Q, even if I hate numbers?',\n",
       " 'How can I really make up my mind and get rid of my bad habits like procrastination?',\n",
       " 'Was there any relationship between Napoleon and Ali Pasha of Tepelene?',\n",
       " 'Where are presynaptic neurons found?',\n",
       " 'What ways will a narcissist mother punish her child for going no contact if child goes back to contact with her?',\n",
       " \"Can I start freelancing after finishing Udacity's Android basic nanodegree?\",\n",
       " 'What is the reason why we really need Bitcoin?',\n",
       " 'What are some good songs for a long journey?',\n",
       " \"If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?\",\n",
       " 'What should be added to thrice the rational number -8/9 to get 4/7?',\n",
       " 'In a four movement symphony, what is typically the form of the second movement?',\n",
       " 'What are various stock exchanges?',\n",
       " 'I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?',\n",
       " 'Which races have the smallest penis?',\n",
       " 'What do the terms Computer Architecture, Microarchitecture and Instruction set Architecture(ISA) mean?',\n",
       " 'Are iPhone users psychologically trapped in brand naming and avoiding to complain about very reasonable missing features such as battery life performance, that iPhone lacks while other flagship in 2017-2018 are doing doing much better?',\n",
       " 'How long is one semester in Ontario?',\n",
       " 'Why do females find penises ugly?',\n",
       " 'What are the best ways to add flour to a homemade chili?',\n",
       " 'What advice do you have for anyone who wishes to accomplish what you have?',\n",
       " 'How do overcome my extreme fear of insects and bugs?',\n",
       " 'What are some examples of durable work gloves?',\n",
       " '2 cars move 6 miles towards each other and then move 8 miles in oppostie direction, what is the distance between them?',\n",
       " 'What apps do you use the most for work in a given day?',\n",
       " 'Can R only take a maximum 100 headers in a dataset? I noticed it will only print the first 100. Is there anyway to change that?',\n",
       " 'How do I marry an American woman for a Green Card? How much do they charge?',\n",
       " 'What do companies look for when recruiting expat? Does the nationality of the candidate play a huge role?',\n",
       " 'Can transcranial magnetic stimulation (TMS) be used to increase cognitive performance?',\n",
       " 'But, why did George Washington free his slaves after what had happened in the Revolutionary War? I think he should have',\n",
       " 'Has the time come for India to adopt one-child policy?',\n",
       " 'Can a US embassy deny a US citizen entry into the embassy?',\n",
       " 'What should I wear to a 1920s party?',\n",
       " 'Why should we test an energy meter periodically?',\n",
       " 'What is the best stationery for the home office vs the regular office?',\n",
       " 'Where can I find genuine aviation jobs?',\n",
       " 'Why do nonprofit organizations treat their employees so badly?',\n",
       " 'What is the procedure to invest in mutual fund?',\n",
       " 'What is osn?',\n",
       " 'What is the most aesthetically pleasing shade of green?',\n",
       " 'Is it wise to do M.Com (2017-2019) in Calcutta University and start preparing for CAT 2018?',\n",
       " 'What is the difference between a politician and a leech?',\n",
       " 'Why does China not sponsor a regime change in North Korea?',\n",
       " \"Why do Europeans say they're the superior race, when in fact it took them over 2,000 years until mid 19th century to surpass China's largest economy?\",\n",
       " 'Why does the cytoplasm built up inside my lip?',\n",
       " \"If I'm creating an app using multiple programming languages, can I use the same IDE?\",\n",
       " 'What are the good and bad neighborhoods of Chuncheon, South Korea?',\n",
       " 'How was your CPSS/PABT at 4AFSB Varanasi?',\n",
       " 'Has someone wrongfully jumped to conclusions about you?',\n",
       " 'How can I start troubleshooting a Hewlett-Packard printer?',\n",
       " \"Isn't it unfair that only men has military duty in South Korea?\",\n",
       " 'How did NSF spinoff from NSFnet helped Sun Microsystem?',\n",
       " 'How dangerous is South Africa for a tourist?',\n",
       " 'Have you ever known someone who has drastically changed?',\n",
       " 'Why is university of Louisville not listed in QS ranking?',\n",
       " 'Did Julius Caesar bring a tyrannosaurus rex on his campaigns to frighten the Celts into submission?',\n",
       " 'How will mercury (debilitated) dasa for Simha lagna be?',\n",
       " 'What are the drivers of Globalisation?',\n",
       " 'What are some people with a high emotional intelligence?',\n",
       " 'Why do womens (mainstream) fashions change so much compared to mens?',\n",
       " 'What is the cause of magnetic force in magnet?',\n",
       " 'How are the Nike football towels manufactured?',\n",
       " 'Who would win, Anizara (Powered Up) from Dragon Ball Super anime episode 121 vs Mystic Gohan (Powered Up) from Dragon Ball Super anime episode 121?',\n",
       " 'Which 4G phone should be best?',\n",
       " 'Is it my fault that my teen daughter has bad social anxiety?',\n",
       " 'Sunil and Raju are absent today? Is or are? Which is appropriate?',\n",
       " \"In what manner has Republican backing of 'states rights' been hypocritical and what ways have they actually restricted the ability of states to make their own laws?\",\n",
       " 'Would Europeans continue to participate in the Arab war for the destruction of Israel and killing all the Jews, if they knew that god himself defends Israel and he will do to Europeans what the Arabs want to do to the Jews?',\n",
       " 'How do you start a conversation on Quora?',\n",
       " 'Which PHP framework should I choose for a website like OLX?',\n",
       " 'What do you do as a forensic psychologist?',\n",
       " 'What can I do to be a better student in school?',\n",
       " 'Why does Fortnite lag everytime I’m fighting someone?',\n",
       " 'What are 5 examples of neurotransmitters?',\n",
       " 'Why are puppies so hyper?',\n",
       " 'Is Jhargram, Birbhum a safe place to visit in winter or there is any fear of terrorist or something?',\n",
       " 'How can I discover the one thing to change my life instantly?',\n",
       " 'Why does my puppy lick his paws?',\n",
       " 'Which is best powerbank for iPhone 7 in India?',\n",
       " 'If an average NFL team obtained a kicker who could consistently make a field goals from 100 yards, would they win the Super Bowl?',\n",
       " 'Can I kill myself now?',\n",
       " 'How can one earn from trading in derivative market?',\n",
       " 'What are some of the fastest cars in the world?',\n",
       " \"When can we know God's timing?\",\n",
       " 'What should I learn after HTML&CSS to become a good Front-End developer?',\n",
       " 'Why do Lingayats bury their dead rather than burn like the other Hindus?',\n",
       " 'Is there a therapist who can help me regarding mental health issues?',\n",
       " 'What is the remaining useful life for a Honda Step WGN with a mileage of 170000?',\n",
       " \"Do you think it's a sign of progress that Singaporeans are adopting British, American, and Australian accents?\",\n",
       " \"I'm the DS Pokémon Diamond game, how do you get to the top of Mt. Coronet?\",\n",
       " 'How do I create a merchant tracking system?',\n",
       " 'What is your life like 5 years from today?',\n",
       " 'Why do people smoke clove cigarettes if they are very harmful?',\n",
       " 'How is Arnab Goswami able to ignore so many defamation cases against him while Kejriwal is being dragged to court everyday on such cases?',\n",
       " 'Which is the best Institute for Big Data Hadoop course in Chandigarh?',\n",
       " 'What is the clipboard feature on a computer?',\n",
       " 'What is the best place to buy maths/physics T-shirts?',\n",
       " 'Does the people who are rich and still claim reservation have any conscience? Why are they given reservation if are rich?',\n",
       " 'Are there instances of Medieval Latin text being later \"translated\" into Classical Latin (for the purpose of comparison)?',\n",
       " 'Which location is the best for an investment in Gurgaon?',\n",
       " 'Both me and my husband are having myopia. I want to prevent our child from this (not yet conceive).is it possible?',\n",
       " 'How does it feel to travel 1500mph in a fighter jet from the airforces?',\n",
       " 'Which book is good for power electronics?',\n",
       " 'How is it possible to make directory on Linux with size of Megabites? How does it happen?',\n",
       " 'When going to an interview, is it a good idea to wear a black shirt with the suit, or wear the standard white or other light colored shirt?',\n",
       " 'Does every stammering have melodious voice?',\n",
       " 'What are the five types of personal fouls in basetball?',\n",
       " 'Why are Americans, British, Canadians, Australians and New Zealanders considered to be separate nations even when they all speak the same language?',\n",
       " 'Which is best changer for Redmi note 4?',\n",
       " 'At what point do you give up trying to stay friends with someone?',\n",
       " 'What are the characteristics that define the frequency division multiple access (FDMA)?',\n",
       " 'How we can Use new line in vb can you explain with example?',\n",
       " 'Do you want a funeral? If so, what for?',\n",
       " 'If both Honey Singh and Justin Bieber fall from the 5th floor, who will survive?',\n",
       " 'What makes you laugh the most and the loudest?',\n",
       " 'Do you have to hold a professional state license to be a mandated reporter?',\n",
       " 'What is the worst emergency that has occurred on ISS?',\n",
       " 'What is cost of guru granth sahib Punjabi?',\n",
       " 'What women feel when she ruin the life of man by falsly accused him for rape/domestic violence?',\n",
       " 'Who built Fort Louis in Pondicherry a particular name?',\n",
       " 'What is the best Nootropics stack that balances performance and risk?',\n",
       " 'How hard is it to be accepted to CS MSc at Université de Montréal?',\n",
       " 'With the introduction of GST, what is the meaning left of Maximum Retail Price of products as there is one nation one tax now?',\n",
       " 'Why are liberal minorities so voilent towards poeple with diffrent poltical beleifs? Should supporting trump be a sentence to be imprisoned or savegely attacked?',\n",
       " 'Is 1 trillion dollars enough to create the Starship Enterprise?',\n",
       " 'What are the mating habits of alligators?',\n",
       " 'How did Meetic become publicly quoted in 2005?',\n",
       " 'Which is better to use, Avro or ORC?',\n",
       " 'How old would Neil Armstrong be today?',\n",
       " \"Why doesn't Telemundo film most of their telenovelas in the United States and not Mexico although the Telemundo headquarters are in Florida?\",\n",
       " \"Can you return a new vehicle if you don't like it?\",\n",
       " 'Which is better PSU to join between oil and ONGC? I have been selected in both the companies for the same profile and same pay as is the case in PSUs. Which company should I prefer and why?',\n",
       " 'What are some of the \"undervalued\" technologies now that you see will make a big impact in the future?',\n",
       " \"What is the main role of carbohydrates in a human's diet?\",\n",
       " \"Can we all now admit that President Trump doesn't really want Congress to pass legislation replacing DACA to protect dreamers?\",\n",
       " 'If you are from EEE branch at Manipal, can you pick up any coding or IT related subjects as minor?',\n",
       " 'How does website like ohmagawd.com or 9gag.com make money?',\n",
       " 'What area some steps that I need to take in my Ph.D. in order to be able to launch a consulting firm right after it?',\n",
       " 'Can you leave a battery blanket plugged in over night?',\n",
       " 'How do you feel about relationships with people who are disabled?',\n",
       " 'Sourcing and procurement Folks, have you used a CRM (like Salesforce) to manage your vendors/suppliers and contracts? If not, then what *do* you use?',\n",
       " \"What does it mean that my boyfriend of 3 years almost always has 2 or 3 ejaculations without losing an erection when he is with me? It's great. But is that normal?\",\n",
       " 'Where is Srinagar Garhwal and what are the places to visit there?',\n",
       " 'What happens when you are accused of plagiarism?',\n",
       " 'Why do people need to talk about their pain?',\n",
       " 'Where do I buy best dry fruits in Hyderabad India?',\n",
       " \"I have a best friend and I want to spend some personal time with him, but he keeps inviting other people to come join us, how do I tell him I want some 'us' time without him thinking weird of it?\",\n",
       " 'How can I install FIFA.18-DUPLEX on PS3 through a USB?',\n",
       " 'What are the characteristics of Performix SST fat burner?',\n",
       " 'Do icy cold water help pain in hand?',\n",
       " \"When will the Gulenist movement stop being falsely accused of crimes it didn't commit, and stop being oppressed?\",\n",
       " \"Is there a time you felt like killing yourself because you couldn't escape an eternal torment of the same thing over and over?\",\n",
       " 'How do you germinate hen and chicks poppies?',\n",
       " 'Which college majors will increase my chances of getting a high paying job?',\n",
       " 'How to download mp3 song with artist photo?',\n",
       " 'How many robots work in New York City?',\n",
       " 'What does run app for 30 seconds mean?',\n",
       " 'Woes mercury and Venuas have a moon?',\n",
       " 'Can dogs actually cry out of sadness?',\n",
       " 'The American economy is growing under Trump’s presidency, why do people still hate Trump as a president?',\n",
       " 'What are the scope of electronics and communication branch?',\n",
       " 'As of April 2018, what is Barack Obama current up to? How is he spending his time and energy?',\n",
       " 'When is leverage investment (ie., borrow to invest) a viable option?',\n",
       " 'Which is the best projector under 30000 rupees?',\n",
       " \"What's the scariest thing that ever happened to anyone?\",\n",
       " 'How do I make a gravitational wave transmitter antenna?',\n",
       " 'Is RLE International (Chennai branch) worth for career development?',\n",
       " 'Is there a difference between watching videos for knowledge vs reading for knowledge? Which medium leads to the best outcome?',\n",
       " 'How are we supposed to get these guys out of Spider-Man web ball?',\n",
       " 'What is an example of Pakkstani-Indian collaboration?',\n",
       " 'Is there a chicken breed that is known for producing extra large yolks regardless the size of their eggs?',\n",
       " 'Is settling in Germany easy?',\n",
       " \"Is Trump's speech at the Value Voters Summit a presidential endorsement of homophobia?\",\n",
       " 'What are + R,-R,+I,-I groups in organic chemistry?',\n",
       " 'What is the diff () serotype and biotypes of bacteria?',\n",
       " 'What component can you use to transition from 5DCV to 230ACV?',\n",
       " \"I'm considering to buy a bike, a 1000cc Japanese one. Which is better, CBR1000RR, R1, GSX-R 1000, or the ZX-10R?\",\n",
       " 'Which is the most culturally diverse city the United States?',\n",
       " 'If energy can neither be created nor destroyed, then how does it even exist (because no one can create it)?',\n",
       " 'What is the procedure to get admission in IPU for LLB?',\n",
       " 'How do I win my divorce over my narcissistic ex?',\n",
       " 'What would happen if every iPhone ever sold exploded at the same time?',\n",
       " 'How do I redecorate my room without money?',\n",
       " 'How much time would it take for China to destroy the whole India?',\n",
       " 'Is 26 too late to learn programming and make a career in it?',\n",
       " \"Why don't poor countries print more money to use for paying for education, etc.?\",\n",
       " 'Who do you like more, My chemical Romance or Elvis Presley?',\n",
       " \"The girl I'm talking to isn't looking for a romantic relationship. Should I ask if there's a possibility in the future?\",\n",
       " \"Why do all the people who claim Florida has great weather go silent every time there's a new hurricane?\",\n",
       " 'Should I factory reset my MacBook or get a new computer?',\n",
       " \"Could the leader of Iran be dead many years ago and the leader of today's Iran is actually a fake leader?\",\n",
       " 'What are some quotes from Tomás de Torquemada?',\n",
       " 'Which programming language should I learn to open a software company?',\n",
       " 'Is laser a good option to remove these blavk lines around my nose?',\n",
       " 'What are some spicy Italian food recipes?',\n",
       " 'How can low productivity lead to lower incomes in a closed economy?',\n",
       " 'How can you tell a jerk from a narcissist?',\n",
       " 'Have you ever run an online background check on someone? What prompted you to do it?',\n",
       " 'Which software do I prefer good for GST billings?',\n",
       " 'What is the largest rattlesnake that can be found in Florida?',\n",
       " 'Do you think we all deserve happiness?',\n",
       " 'Why do the Liberals who run schools choose not to have controlled access? The kids in Florida were killed due to an unlocked door.',\n",
       " 'Among these practices, which do you consider as strenghts that any preschool should possess?',\n",
       " 'How does the society react during your term breaks at NDA?',\n",
       " 'Do intelligent people ask questions?',\n",
       " 'Why do I feel sad watching my parents age?',\n",
       " 'How can I use Python in biological researchers?',\n",
       " 'Was Count Dooku a Sith Lord?',\n",
       " 'What led to the success of British efforts to claim the territory where Aboriginal Australians lived?',\n",
       " 'Is there any typing app on Bodhi Linux?',\n",
       " \"Why aren't lives of all animals equal?\",\n",
       " \"How can I legally use a web link in a court of law if that link doesn't exist anymore?\",\n",
       " 'What is input subsidy?',\n",
       " 'How can I create the most exciting essay to read?',\n",
       " 'Why did Pakistan pass the Sikh Marriage Act before India?',\n",
       " 'What is another word for \"hello\"?',\n",
       " 'What’s it like living in the ghetto?',\n",
       " 'Is there a good Christian devotional about dating?',\n",
       " 'What are the main working of big data?',\n",
       " 'How can I prevent my septic tank from overflowing?',\n",
       " 'What does the average survivor of 9/11 and families of the victims think about what really happened that day, esp. fire fighters who were there?',\n",
       " 'When did late medieval middle easterners, near easterner, nomads, and mongols eat their meals?',\n",
       " 'How can the psychology of aging be explained?',\n",
       " 'Which app is best to listen to kpop music?',\n",
       " 'Is our nationalism on social media only?',\n",
       " 'Where is the best place for window tinting in Greenville SC?',\n",
       " 'Why does the HR guys in my company gives me cold shoulder?',\n",
       " 'What is the process of issuing corporate bonds?',\n",
       " 'What are some useful tips for someone who is starting work at Raymond James?',\n",
       " 'How did you lose that last layer of stubborn fat?',\n",
       " 'Which engineering branch should be choose to apply for junior scientist in ISRO?',\n",
       " 'What creative jobs can I take up and where?',\n",
       " 'How do I train my dogs to kill raccoons?',\n",
       " \"Would you forgive your husband if you caught him having sex with his favorite celibrity? If he later says he couldn't control himself as his lifetime fantasy was becoming true.?\",\n",
       " 'Can downloading pirated content be considered as a violation of the second precept of Buddhism?',\n",
       " 'Why is it that arranged marriages which happened in our previous generation have greater chances of surviving the entire life duration as compared to the ones happening in our generation?',\n",
       " 'What is a good example explaining \"Occam\\'s razor\"?',\n",
       " 'Why does life gives pain and sadness?',\n",
       " 'How can I tackle obsession?',\n",
       " 'What are the advantages and disadvantages of Automatic Headlamp On (AHO) especially in two wheelers in India?',\n",
       " \"What things doing daily will change one's ecomonic condition and personality?\",\n",
       " 'What is the best way to learn manga drawing?',\n",
       " 'When writing manual test cases and scripts, how much detail is too much detail when documenting the steps?',\n",
       " 'What are some small yet important battles that occurred in WW2?',\n",
       " 'Is this the best time to buy a Kyber token at 1.11$ as of the 16th of Oct 17′?',\n",
       " 'Why did my taskbar stopped responding?',\n",
       " 'What are the best way to answer a question on Quora and get more up vote?',\n",
       " 'Can I use images from other blogs just giving credit to the original author?',\n",
       " \"Shouldn't Republicans be given a free pass to run the government any way they see fit?\",\n",
       " 'Did the British parliament just abolish itself?',\n",
       " 'How can I apply for TOPIK exam in India online?',\n",
       " 'What is better than steak?',\n",
       " 'Dis advantages of education?',\n",
       " 'Is there a way to start a MongoDB server from a mongodump without having to use mongorestore?',\n",
       " 'Why do people feel hesitate or humiliate while speaking Hindi?',\n",
       " 'How should I prepare for ESE 2019 (civil) if I had 200-204 marks in ESE 2018 and I am in my last semester of college?',\n",
       " 'Ingredio milk shake was harmful to use long time?',\n",
       " 'What are some examples of motion- Without Force?',\n",
       " 'What is Transient Voltage?',\n",
       " 'What is bass heads?',\n",
       " 'Why is the poem \"Ramayana\" one of the largest ancient epics in world literature?',\n",
       " 'Is there any woman (other than Muslim) who is happy after marrying a Muslim guy, as there are a lot of answers on Quora about love jihad, and all of them suffered a lot after marrying a Muslim guy?',\n",
       " 'How does the chain rule work?',\n",
       " 'What happens when a computer needs to be accessed for an investigation? What tools do the police use?',\n",
       " 'Are there many famous polygamist celebrities in modern day Indonesia today?',\n",
       " 'Which are the best trusted sites for applying scholarships in class 11? I scored good marks in 10th.',\n",
       " 'Which book is best in British history for graduation?',\n",
       " 'What is the best free online lecture video site for neet PG and MBBS?',\n",
       " 'How good is the Bachelor of Information Technology from the University of Queensland Australia?',\n",
       " 'How does the rise of China change the view of dictatorship?',\n",
       " 'If it possible to score a good sectional percentile in LRDI by only solving DI questions?',\n",
       " 'How is the best way to speak English like a British?',\n",
       " 'How can I do scientific research and get published at age 15?',\n",
       " 'Which are the best places to party in Bangalore?',\n",
       " 'Is it safe to invest larger amount of money in online stock market trading in India? If not what would be the alternative solutions?',\n",
       " 'How much does increasing funding for education increase the quality of education?',\n",
       " 'Why do bushfires happen?',\n",
       " 'What are the best ways to clean your Remington Woodmaster model 742 .30-06?',\n",
       " 'Why do police officers get to go on paid administrative leave before getting fired where the average joe just gets fired? Who negotiated this inequality?',\n",
       " 'How can I become certified in Revit?',\n",
       " 'What is the primary cause of Post-Traumatic Stress disorder in the Military?',\n",
       " 'Is a soy latte a healthy drink?',\n",
       " 'Why would a deployed Army Ranger ask for a Steam Gift Card?',\n",
       " 'Which type of clutch is used in Activa?',\n",
       " 'In psychology, what is compliance?',\n",
       " 'As an exceptionally or profound gifted individual, which way of thinking is most dominant, verbal or non-verbal?',\n",
       " 'How much weight can I stack on top of my laptop?',\n",
       " 'How do I become scientist after class 12?',\n",
       " 'Why if a man who has had me over 5 times. Who we both know are attracted to and like each other, ask why I came when he asks me over? Is he looking for confirmation? When there I stay for 3/4 hours at a time.',\n",
       " 'How much a new lawyer earns in India? And how many types of lawyers are there?',\n",
       " \"My Samsung Galaxy S6 edge is not being recognized by any PC's or USB flash drives. How can I fix this issue?\",\n",
       " 'What would have Stalin thought of the late cold war era Soviet Union?',\n",
       " 'Which army was better, Spartan or Roman?',\n",
       " 'What should I reply when I ask my friend for a little help and he tells me jocularly that I will have to pay for his help?',\n",
       " 'What are the steps to become an analyst in cricket (be it video or data)?',\n",
       " 'What are some characteristics of deoxyribose and ribose sugar?',\n",
       " 'Do moms have sex with their sons?',\n",
       " 'Is dear Zindagi a good movie?',\n",
       " 'What is it like to work as an employee for Oprah?',\n",
       " 'Why did the Pope say that \"Muslims are a curse to this world\"?',\n",
       " 'What is the meaning of relationship with a girl from two year?',\n",
       " 'Which MBA program is suitable for a doctor in the field of private practice for over 30 years?',\n",
       " \"Why didn't the Romans conquer Ireland they failed to conquer Scotland?\",\n",
       " 'How much money do I need to buy a gas station?',\n",
       " 'What is the ladder operator method for determining the energy eigenvalues in a quantum harmonic oscillator?',\n",
       " \"If XRP doesn't gain mass adoption, what would most likely be the causes?\",\n",
       " 'What animals are native to Spain?',\n",
       " 'Can coffee make you more productive?',\n",
       " 'Create the most advanced animal ever from currently living or extinct species…?',\n",
       " 'Where is a good place for filming time lapse videos of planes landing in Heathrow airport?',\n",
       " 'What are the roles of Royal British Guards?',\n",
       " \"Excluding online / e-commerce businesses like Uber & AirBnB, what's the best referral program you've heard about or used?\",\n",
       " 'What was the main reason of conflict between Suhrawardy and Bhashani?',\n",
       " 'Can I buy airticket with Amadeus after booking it? And how?',\n",
       " \"Why can't I become a businessman?\",\n",
       " 'Can weed be a good antidepressant?',\n",
       " 'How much is the world worth?',\n",
       " 'If you had to choose between Instagram and Quora, what would you choose?',\n",
       " 'What is the past form of must have been?',\n",
       " 'What are some of the good textbooks for learning philosophical logic for an absolute beginner?',\n",
       " \"How can we Indians make Sri Lankan people understand that India created and funded the LTTE for the benefit of Sri Lanka itself and India didn't have any ill intentions?\",\n",
       " 'What is the best way to consume a lot of educational material?',\n",
       " 'Can my followers see my anonymous questions? (Since 2017 anonymity changes)?',\n",
       " \"How does Lady Macbeth plan to kill Duncan in Shakespeare's play?\",\n",
       " \"Why don't the Gulf Arab post pictures of women in their countries?\",\n",
       " 'How free or democratic is in the USA? What does it mean to you personally?',\n",
       " 'What are the modern superstitions blindly believed by educated masses?',\n",
       " 'How can I convince a 6 year old to eat healthy?',\n",
       " 'What are the disadvantages of using React Native for developing native apps (e.g. instead of Swift)?',\n",
       " 'What is the mindset and motives of the westerners who join ISIS?',\n",
       " 'How do I become a Delivery partner at Amazon?',\n",
       " 'Who is the sexiest female in the world?',\n",
       " 'What happened to LSI Corporation?',\n",
       " 'I almost constantly feel uneasy. Why?',\n",
       " 'How can I find a government job?',\n",
       " 'What is the difference between a split squat and a lunge?',\n",
       " 'Where can I download test bank for Entrepreneurship The Art, Science, and Process for Success, Bamford, 2e?',\n",
       " 'How many students appear for Imucet every year?',\n",
       " 'How peoples in India seems hypocritical about womans empowerment?',\n",
       " 'What does a certified energy auditor do?',\n",
       " 'What really happens in \"flapping/r-voicing\" English dialects when unstressed /t/ or /d/ are preceded by /n/ (e.g. /nt/ and /nd/ in \"winter, blender\")? Is it a nasalized tap [ɾ̃], [nɖ], [nɾ] or just [n] with the /t, d/ dropping (winter-winner merger)?',\n",
       " 'Who are you going to meet, if you go to heaven?',\n",
       " \"Why wasn't John Diggle the Green Arrow in Crisis on Earth-X? Arrow S6E7 seemed to conclusively show him taking up the mantle.\",\n",
       " 'Do the royals prefer William to Harry?',\n",
       " 'Is it necessary to disclose your salary from the last employer while interviewing in a new company in IT?',\n",
       " 'How many optionals are there in up pcs 2017 exam?',\n",
       " 'Why is Relational Algebra s the basis for relational databases?',\n",
       " 'What is the difference between structural breaks and regime shifts?',\n",
       " \"What's some of the biggest book discussion websites/forums?\",\n",
       " \"When did DeviantArt's fetish culture become as prevalent as it is now? And how can the site moderate this content better without being too tyrannical?\",\n",
       " 'On what day are checks being mailed out for July?',\n",
       " 'What kind of therapy can help you forget a memory? Does hypnosis actually work?',\n",
       " \"Why at times I can sing perfecty and can hit every single note easily, and then at times I stuter when I speak and can't even sing and become out of breathe?\",\n",
       " 'Which black superhero can beat Superman or is as strong as him?',\n",
       " 'What is the difference between a maverick and an indecisive person?',\n",
       " 'Why do trading card game copanies pretend like kids are their main demographic when 90% of their customers are above 20 years old?',\n",
       " 'What different magic does the Lucas sequence have than the Fibonacci?',\n",
       " 'What did you buy on a hunch that turned out to be the smartest investment you ever made?',\n",
       " 'Can I crack JEE Advanced with AIR 1 if I study one year having good basic knowledge?',\n",
       " 'How much more political fumbling will it take for Republicans to turn on Trump?',\n",
       " 'What is the most recognizable short story?',\n",
       " 'Does the skin get affected after shaving the hair (skin on arms and legs)?',\n",
       " 'How can I use real time database on my WordPress website?',\n",
       " 'What are the procedures (FORMS) to be followed to accept loans from director is a NRI?',\n",
       " 'What if the Indians had been in place of the Red Sox in the 2007 World Series?',\n",
       " 'Why are citizens of The Netherlands called Dutch?',\n",
       " 'Why do so many Asians wear masks?',\n",
       " 'What are the Chinese fortune sticks meanings?',\n",
       " 'How can I find out the carrier by only using the tracking number in the UK?',\n",
       " 'Why do I love starting fights and making people angry?',\n",
       " 'Should I use my brain more?',\n",
       " 'How does the electrostatic force f revolving electron becomes equal to the centripetal force?',\n",
       " 'How does bikini look like?',\n",
       " 'What is a 1969 100 dollar worth?',\n",
       " 'Why did my clock stop at 3:00 in the morning?',\n",
       " 'What is the difference between dimension table and fact table?',\n",
       " 'How dangerous of an animal is a mandrill?',\n",
       " \"What are some ways for a layperson to profit from a country's currency failing?\",\n",
       " 'How can certain pro-lifers call themselves that when they believe a woman should die than have an abortion to save her life?',\n",
       " 'How is asking a data scientist to analyze the national economy different than asking an economist to analyze the same economy?',\n",
       " 'How can I get Bansal classes sheets?',\n",
       " \"Aren't religious people afraid that their deceased loved ones are watching them while they're using the bathroom, masturbating or having sex?\",\n",
       " 'How much weight can a toy wooden boat hold in kilograms?',\n",
       " 'Is there a way to report a business review of your business on Facebook? How do you do it?',\n",
       " 'Which models does the Chevrolet Caprice PPV primarily compete with? How do they compare?',\n",
       " 'What type of franchise can be thought of in a city like Surat (Gujarat) with a small investment?',\n",
       " 'How do I score good marks in economic application for ICSE examinaton?',\n",
       " 'How does radar guidance for anti-aircraft guns work?',\n",
       " 'Why was a non-offensive photo without nudity or profanity deleted?',\n",
       " \"Why are Chik-Fil-A's restaurants always so nice compared to most other chains?\",\n",
       " 'Is there any way to get insurance of damaged two wheeler?',\n",
       " 'What are my chances to grab an MBBS seat under 85% state quota in West Bengal with 437 marks in NEET 2017 in a government college?',\n",
       " 'What are some unique live/study abroad experiences that you have?',\n",
       " 'When he has to go somewhere or take or do something for his sister, he says I can go but when I do 5 min in the car ride he starts a fight and accuses me and says im ruining his day why?',\n",
       " \"What does curvature of space time mean. We know that there isn't a humongous net in space that is curved, so what is it?\",\n",
       " 'Why do Americans prefer just to not show up somewhere rather than face even the mildest of conflicts? (My colleagues and I have noted a growing number of people who skip any face to face meetings without any explanation at all.)',\n",
       " 'How harmful is electromagnetic interference?',\n",
       " 'How can I distinguish between relative scales such as B-flat major and G-minor or C major and A minor?',\n",
       " 'Do we feel our breath?',\n",
       " 'What are the reasons for drug trafficking?',\n",
       " 'What should the normal fetal heart rate be during pregnancy?',\n",
       " 'How can shoulder pads protect you in American football?',\n",
       " 'My ex-girlfriend and I live in different countries, we are very much in love, and cannot be together for 3 more years. What should we do?',\n",
       " 'What are the similarities between communication and information?',\n",
       " 'Which company can I apply in web development domain having 2 years of experience in Cognizant?',\n",
       " 'What happens if I drink 1 can of Monster Energy?',\n",
       " 'Which is the biggest alphabet in the English dictionary?',\n",
       " 'Who invented the modern portfolio theory?',\n",
       " 'Can we convert heat directly into elecric energy without a cold body?',\n",
       " 'Is Finix Coin ICO legit or scam?',\n",
       " 'How good are my chances of getting accepted for PhD at MIT, Caltech, Berkeley? See comments for details.',\n",
       " 'Is 0.888… equal to 0.999… because of rounding?',\n",
       " 'Why is India actually called as India?',\n",
       " 'What causes weevil infestations at your home?',\n",
       " 'Why does my boyfriend give me the silent treatment?',\n",
       " 'What is the history of matrices in computer science?',\n",
       " 'How do you stop making mistakes when playing chess?',\n",
       " 'What is the best step to work as a freelance writer?',\n",
       " 'Why would you expect to have dilute urine with Addisons disease?',\n",
       " 'What is supercharging in IC engine?',\n",
       " 'Does stiffness attracts load in beams?',\n",
       " 'What are Somen well designed social experiments?',\n",
       " 'If reincarnation is not true, why do some people remember their past lives?',\n",
       " \"Why super respectful and successful entrepreneurs who are millionaires or billionaires don't want to be lead in politics?\",\n",
       " 'Who is likely to be fluent in English: a Ghanaian or a nigerian?',\n",
       " 'Who is objectively the most powerful character in the Marvel/DC universes?',\n",
       " 'Why are all of the most popular comments on NYT are against the memo, whereas the ones on WSJ are pro-memo, given NYT and WSJ have similar political bias?',\n",
       " 'What does the diet of the mantis shrimp consists of?',\n",
       " 'Is the term \"linguistic differential\" an actual linguistic term?',\n",
       " 'Why do so many people decide against Graph Databases? Scalability? Not enough experts? Mostly \"unconnected\" data to start with?',\n",
       " 'What is your opinion on chicken waffles?',\n",
       " 'What is the best diet for teddy bear hamsters?',\n",
       " 'Have you ever taken your sweet time imagining a fiction book?',\n",
       " 'What is the scope in sound engineering in India and what is the annual income of sound engineers?',\n",
       " \"I just lost a tooth. Why can't I see my new tooth forming? It has been already 4 days.\",\n",
       " 'Is it possible for a human to think faster?',\n",
       " 'Will it be helpful if I drop 1 year and appear for it again if my results this year are not good enough?',\n",
       " 'Liberals are pro-choice, but the choices must be approved by them first. Is this an accurate description of liberals?',\n",
       " 'Is it normal to lose your mucus plug during an early pregnancy?',\n",
       " 'What is the value of Sin^2A+sin^2B?',\n",
       " 'What do the Dutch think of the Roosevelts?',\n",
       " 'Have you ever met or befriended a woman who has enough physical strength and is ready psychologically to overpower, tie up and gag an average man in case of being that necessary for her safety?',\n",
       " 'What software would you recomend in order to find the posts with the most likes on a Facebook group or page?',\n",
       " 'Why are South Indian dishes which are prepared by North Indians more tasty than dishes prepared by South Indian restaurants?',\n",
       " 'How much employment does a super yacht represent? How many people are employed and for how long, in sourcing the materials & then building the vessel?',\n",
       " 'Which private college is good in WBJEE?',\n",
       " 'How can I change my last name in California?',\n",
       " 'What are some practical and possible applications of machine learning in life sciences, ecology, conservation biology, and environmental sciences?',\n",
       " 'How do you load a black powder rifle?',\n",
       " 'Should you be able to name specific companies you have introduced to opportunities if no transaction has resulted?',\n",
       " 'What is a fiduciary? How is it different from a financial advisor?',\n",
       " 'How can we build self-confidence in Women?',\n",
       " 'Why do American firms steal Chinese technology?',\n",
       " 'What proves I was born from another human being? I don’t remember being born.',\n",
       " 'Can I get MBBS seat in govt medical colege in Gujarat if my state ramk is 641?',\n",
       " \"Getting a -000 reading from white wire that's tied to the ground bar what does that mean?\",\n",
       " 'How long do you think it will take for Quora to remove this question? Closest guess wins a prize.',\n",
       " 'Where can I purches some DMT in Orange County?',\n",
       " 'What is the recipe for boiled egg noodles?',\n",
       " 'Is paddy a herb?',\n",
       " 'Do therapists actually care about you like they would a friend or do they care cause it’s their job?',\n",
       " 'What does it mean if I have a light sensitivity and sometimes my head is in pain and it I feel that it will broke into half?',\n",
       " 'Can I get CSE branch in VIT Chennai if my rank is 28777?',\n",
       " 'Is it legal for a debtor or quit their job to avoid a creditors collection efforts and still claim unemployment in California?',\n",
       " 'Among all which software service based companies have higher salary?',\n",
       " 'How long would it take for someone to notice if you suddenly disappeared?',\n",
       " 'How social networking sites work with opinion mining techniques applied on user comments?',\n",
       " 'Are you doing your dream job?',\n",
       " 'Why is Jinping the biggest serial religion murderer and rapist leader of the world after Mao?',\n",
       " 'How is ammonium bicarbonate used in production of bread?',\n",
       " 'Are\\xa0Jat\\xa0and\\xa0Gujjar\\xa0girls beautiful?',\n",
       " 'Does a box of ammo just explode or does each individual bullet go off like fireworks?',\n",
       " 'What is the best method for determining what your values are?',\n",
       " 'What is the difference between impression materials and impression compound?',\n",
       " 'Is someone from SCI Graduate Marine engineers (GME) Mumbai?',\n",
       " 'How do animals defend themselves out in the wild?',\n",
       " 'How do I get a job as an ilustrator?',\n",
       " 'Can California legally require that Tinder stop charging users over 30 years old a higher rate?',\n",
       " 'What is the book \"Nothing Succeeds Like Success\" about?',\n",
       " 'What cold war and its effects?',\n",
       " 'Why has polythene been banned in our state and country?',\n",
       " 'Do State Bureaus of Investigation investigate homicide more than the FBI does?',\n",
       " 'How religious are Tunisians?',\n",
       " 'Is it difficult for animal welfare charities to compete against those that benefit humans, epecially when many of us have limited funds to contribute?',\n",
       " 'Why should you consider taking a train ride from Philadelphia to Baltimore?',\n",
       " \"What are Howie Seago's major accomplishments as an actor?\",\n",
       " 'What are the risks of bleeding and clotting during early pregnancy?',\n",
       " 'Do animals make noise when having sex?',\n",
       " 'How is it that I can get 6 to 8 hours of sleep before my graveyard shift and still have trouble staying awake for my 7 hours of work?',\n",
       " 'What is considered a babyface in WWE?',\n",
       " 'What are the new topics for research in Human Resource management?',\n",
       " 'What are the challenges that Lori Anne Allison has faced as a makeup artist?',\n",
       " 'What are some of the most remote areas in the world?',\n",
       " 'Where can one apply for aadhar in bandhup West lbs Marg?',\n",
       " \"What are objective criteria in evaluating cell's health in culture?\",\n",
       " 'What is the salary range of the salary of rich people?',\n",
       " 'What happens to those who have less than 75% attendance?',\n",
       " 'Who is the worst USA president, Bush or Trump?',\n",
       " 'I have corrected only my exam centre in NEET form do I have to pay any correction fee?',\n",
       " 'Do you know about Mumbai call girl service?',\n",
       " 'What is the full procedure of cutoff based admission in Delhi University?',\n",
       " 'What is the longest practical distance that light rays could converge? (on earth, in a standard atmosphere)',\n",
       " 'Why did Captain Phasma give up so easily? I, personally thought that she was going to somehow resist or trick the gang.',\n",
       " 'What is scope of BA?',\n",
       " 'Why there is lots of suicide?',\n",
       " \"Is it racism what this Australian girl did to me? I'm Asian.\",\n",
       " 'What do you think about the protests against Padmaavat (Padmavati)?',\n",
       " 'How did we decide that the earth rotates from west to east?',\n",
       " 'How can I be a great footballer?',\n",
       " 'What is the diff between LTE and volte phone in providing facility?',\n",
       " 'Prevent forwarding of your WhatsApp videos?',\n",
       " 'What songs should we play during the cocktail hour at our wedding?',\n",
       " 'How common is injury due to friendly fire in military operations?',\n",
       " 'Where can I find a free carpet installation invoice template?',\n",
       " 'Why do people on Quora not answer my question about gun control? I just want to debate with people who support gun control, but no one answers it.',\n",
       " 'Why do I always mess everything up?',\n",
       " 'When will the US stop supporting Kosovo terrorists (Albanians), who are actually the same as ISIS?',\n",
       " 'What 1890s born celebrities were still alive in the 1990s?',\n",
       " 'How do sex workers handle and secure their cash earnings?',\n",
       " \"I have made payment for AA recruitment fee but transaction didn't complete and balance deducted from my bank account and the site is still asking for payment, why so?\",\n",
       " \"I've got 88/200 in MU OET 2018. What branch and rank can I expect?\",\n",
       " 'Has it become more difficult since 2015 to land a job through the USC MS CS program?',\n",
       " 'What should Indian teenager never try in there life?',\n",
       " 'Is the job market bad for experience holders in India currently?',\n",
       " 'Would a famous person on social media ask a fan for something like money or iTunes cards?',\n",
       " \"What are Robin Gibb's major accomplishments as a singer?\",\n",
       " \"Why do Americans need the second amendment? Don't want to start a fight but the right says it is necessary for a democracy and such and why are they so worried about the government.\",\n",
       " 'What is the budget for new year camping in Jaisalmer?',\n",
       " 'What are the best humour or jokes in the world?',\n",
       " 'What role did Leigh Francis develop as the fictional character \"Keith Lemon\"?',\n",
       " 'Will cars be still around in 100 years?',\n",
       " 'Is it true that Chennai is developed because of Telugu people?',\n",
       " 'Is it dangerous to have blood in cough in morning?',\n",
       " 'Why would more people live in one country over another?',\n",
       " 'Is Mack 10 blood?',\n",
       " 'Whatis the difference between a stag and a buck?',\n",
       " 'Can I lose weight without eating eggs?',\n",
       " 'Can a restaurant play loud music in?',\n",
       " 'What are some cultural taboos in Russia?',\n",
       " 'What if I want to start practice after articleship in big 4? If not practice, what are other options available?',\n",
       " 'What does Europeans think of anti semites attacks by Muslims in their countries?',\n",
       " 'How did James Burke become deaf?',\n",
       " 'Is there any directory for IT professionals in Bangalore?',\n",
       " 'Is it possible to suffer from depression without knowing it?',\n",
       " 'How can I disassemble .22 double-action revolvers?',\n",
       " 'Will you be able to play a co-op games between a Nintendo 3DS and the Nintendo Switch?',\n",
       " 'Why is it hard to download games from the Play Store?',\n",
       " 'How do I get cheap flight tickets from Delhi to London?',\n",
       " 'How can I quickly learn breakdance power moves?',\n",
       " 'Is there a stereotype attached to people from Sydney’s northern beaches?',\n",
       " 'Do you think inflation hits rich businessman?',\n",
       " 'Can you make more money as an electrician?',\n",
       " 'Why Indian girls have fetish for White guys?',\n",
       " 'What are some tips to write a summary about \"Until they bring the streetcars back\"?',\n",
       " 'Who is the best broker for a new real estate agent in California?',\n",
       " 'Whats the cleanshot way to express ones feelings to a girl irrespective of the outcome?',\n",
       " 'What are your views on Barkha Dutt switching to NewsX?',\n",
       " \"Would Twitter hire you if you don't have a Twitter account?\",\n",
       " 'How was Swagatham 2018 program by CSA, IISc for GATE 2018 toppers? How people are selected/invited and do they invite only Computer science students or others also?',\n",
       " 'I get 1st place or otherwise in the top three for hashtags on nearly all of my posts, even with million-post hashtags. However I do not get much traffic from that, only getting follows through following. What am I doing wrong?',\n",
       " 'How can I get market research report on kids apparel industry India?',\n",
       " 'What are the different types of consultants and what is the qualification to become a consultant?',\n",
       " \"What's your favourite?\",\n",
       " 'What is the difference in listed and unlisted company?',\n",
       " 'Should I ask any questions?',\n",
       " 'Which are the best books to read for Indian politics and which tells truth about all the political matter?',\n",
       " 'Does an analog energy meter rotate when the load is off?',\n",
       " 'What will people know about Generation Z in 2050?',\n",
       " 'Could the modern Canadian military take on Nazi Germany of WW2?',\n",
       " 'If I throw an ice cube into the ocean, what is the chance that I will come in contact with one of those water molecules (from the ice) again in my lifetime?',\n",
       " 'Why my Acer Aspire V 13 laptop show me \"no battery is detected\"?',\n",
       " 'How can I forcibly convert all Chinese people to Sunni Wahabbi Islam?',\n",
       " 'Can I get a friend from UK or USA?',\n",
       " 'What are the requirements to get in Princeton?',\n",
       " 'How are the two types of urban local bodies constituted?',\n",
       " 'Did the idea of yin and yang originate in China?',\n",
       " 'What should you take into consideration when making a Hank Hill costume?',\n",
       " 'Can a Chinese person start a political party?',\n",
       " 'Why iron is not found in its free state?',\n",
       " 'How fast will humans die If the sun suddenly turn off and solidify maintaining the same gravitational force?',\n",
       " 'How do you search for and find mass graves?',\n",
       " 'Do crime reporters face death threats?',\n",
       " 'Which is the best elevator company in India?',\n",
       " 'Will the end of Net Neutrality help traditional media rebound?',\n",
       " 'Is there any apps for mining bitcoin with paid version?',\n",
       " 'Who was the shortest professional wrestler ever?',\n",
       " 'Which offices or agencies are legally able to arrest a sitting U.S. President?',\n",
       " 'Who are the major jute exporters in Bangladesh?',\n",
       " 'Which university should I apply for a bachelor in the liberal arts in Europe?',\n",
       " \"TUM Masters in communication requires recommender to state that the candidate was in top 20%, why will he do when he wasn't?\",\n",
       " \"My body temperature has increased slightly, but I don't have any feverish feeling. Is there any matter of concern?\",\n",
       " 'What summer internships are available for marketing aspirants?',\n",
       " 'What are the differences between depression and melancholia?',\n",
       " 'How did you manage to overcome childhood adversity to become the person you are today? What were the prime motivators during your journey?',\n",
       " 'What is the genetic background in details?',\n",
       " 'If men have a better pain tolerance than women, does that mean they would handle childbirth, menstrual pain and breastfeeding better?',\n",
       " \"What was the historical significance of Mesopotamia's god?\",\n",
       " 'Why is it ironic about the meaning of salem where so many people were hanged in the crucible?',\n",
       " \"Is it wrong that I love someone I've never met?\",\n",
       " 'Is there anything called love at first sight?',\n",
       " 'Do Akshay Thakre has naag-mani with him?',\n",
       " 'This guy tells everyone that he hates me, but I have never talked to this guy. If he does why does he keep staring at me and try to look at me when I’m not looking?',\n",
       " 'Where is the answer key of mock test for AIIMS 2018 which is distributed tomorrow?',\n",
       " 'Why some LG phone tempature get too high?',\n",
       " 'Can teachers smack students at school in Australia?',\n",
       " 'Why is Aerogel so expensive?',\n",
       " 'Is it ok to walk your dog in the rain, or what are alternatives?',\n",
       " 'What is the plural of \"Mathematics\"?',\n",
       " \"Why do people act like having sex is this amazing thing and everybody else should want to have it? I don't care if people enjoy sex if they're happy, but I hate when they act like my asexuality means I'm either missing out on life or being childish.\",\n",
       " 'How much does it cost to live in Paris for a month?',\n",
       " 'How can I say (and write) \"Are you Tibetan?\" in Tibetan?',\n",
       " 'How do you change the wording in a Groupon review that I already submitted?',\n",
       " 'If Jorge Luis Borges was alive now, where would he publish his short stories?',\n",
       " 'How do you make sure you are implementing the ideas you get from the books you read?',\n",
       " 'What is the point of intersection between y= \\\\sqrt {6-x} and y=x?',\n",
       " 'What is the best way to report fraud by a hospital or medical practice?',\n",
       " 'Why do people on YouTube disrespect my opinions with fake exhausts on cars such as Mercedes-Benz and Audi?',\n",
       " 'Do you shower before breakfast, or have breakfast before showering?',\n",
       " 'Given a constant volume, does pressure drop as gas is absorbed?',\n",
       " 'What is the name of the bird that lives in gir forest and freezes when threatened?',\n",
       " 'Is it possible knowingly to stop your own heart or heartbeat?',\n",
       " 'Doctor injected anesthetic into my skin for minor surgery. I felt a cold rush through my body, but absolutely no numbing in the area whatsoever, I felt it all and it was horrible. Could he have injected directly into my bloodstream?',\n",
       " 'What is cryptorchidism and how is it treated?',\n",
       " 'Why is education better than business?',\n",
       " \"Should I really feel that it's okay not to love or respect women?\",\n",
       " 'Is there a way to switch accounts you signed up with on your Windows 10 PC?',\n",
       " 'Why did most of the colonial empires come out of European countries?',\n",
       " 'You can swap your identity with anyone in the world but you are stuck with their body, money, house, debts and family forever, who do you choose?',\n",
       " \"Does buying a graphic card holding laptop damage the laptop's performance faster than that of a ordinary laptop?\",\n",
       " 'What is the Orthodox Christian argument against \"Filioque?\"',\n",
       " 'How do you know when your boyfriend is bipolar?',\n",
       " 'Economically speaking, were wages higher for men before women entered the workforce?',\n",
       " 'Is the X1 Bike waterproof?',\n",
       " 'What are the most resent challenges in human resources management that need to be addressed?',\n",
       " 'What are those kid gang genre movies like The Goonies, E.T or Stand By Me called?',\n",
       " 'What are some examples of fables and folktales?',\n",
       " 'Why is Snapchat popularity declining?',\n",
       " 'What does the chairman of a regional federal reserve do?',\n",
       " 'Is Canada a better country to pursue MBA in banking and finance after 2 years of experience in Indian banking system?',\n",
       " 'What is the colour of methyl orange in limewater?',\n",
       " 'What causes itchiness in my breasts?',\n",
       " 'Can comrades of Quora answer, who are the IAS, IPS. IFS, IES officers that suffer due to their mentally retarded children?',\n",
       " 'If every other car is autonomous and you had the only non-autonomous car, what would you do?',\n",
       " 'How can I start earning after doing my MBBS other than private clinics? Like how to apply for hospitals and what would be the salary?',\n",
       " 'What is the best collection of amazing facts?',\n",
       " \"Which are some of the world's most dangerous for activists?\",\n",
       " \"Is it bad for a 13 year old girl to be extremely close to a 22 year old girl if they're not related?\",\n",
       " 'How can I train a Yorkie-Pom dog to follow my commands?',\n",
       " 'What are the best running shoes for flat feet?',\n",
       " 'What is the easiest way to convert cubic feet into liters in basic chemistry?',\n",
       " 'Are there any uses of sports certificates at school level in any interview?',\n",
       " 'How many times has the U.S. Air Force failed to send over court martial records to the F.B.I.?',\n",
       " 'What should I do if I’m electrical engineer but very intrested in mechanical machines & equipments?',\n",
       " 'What is future of Administrator in Linux?',\n",
       " 'why do Gopal Krishna Gokhale was considered an important mentor to Gandhi?',\n",
       " 'Where can I buy unique and quirky products online?',\n",
       " 'Game of Thrones, what does Arya find out about Littlefinger?',\n",
       " 'What are some of the foods which should be taken at least once in a week?',\n",
       " \"What's the weight of undergraduate research while applying for Integrated PhD (Physics) in India? Does not having a research paper published after Bachelor degree deter the chances of getting selected?\",\n",
       " 'M.Planning or M.Des, whats better after B.tech in civil engineering?',\n",
       " \"What are some of your 'Bakkushan' moments?\",\n",
       " 'Does walmartlabs give new hire stock grants and how does the RSU vesting work?',\n",
       " 'What do you think will happen to Bitcoin 2018?',\n",
       " 'What is actually happening in Syria with children?',\n",
       " 'If Hispanics are so proud of their countries, why do they move out?',\n",
       " 'What are the job prospects after doing an MSc in Chemistry or Biology?',\n",
       " 'What would you name a cognitive automation solution?',\n",
       " \"Does Facebook record audio on users' devices for ad-targeting purposes?\",\n",
       " 'How is pre-ordering considered bad?',\n",
       " \"Which college I could get with 530 marks in neet'17 specially in UP?\",\n",
       " 'What is the point of speed limits on interstate highways and nonresidential/city roads? Stationing police officers on these roads seems like a huge waste of limited police resources.',\n",
       " 'What are some good tips for ESO?',\n",
       " 'Which dog collars are the best to use when training dogs?',\n",
       " 'Why does Quora have a text limit?',\n",
       " 'What is the easiest way to get rid of debt?',\n",
       " 'How does the multiple-hit hypothesis explain the development of cancer?',\n",
       " 'What happened in the year 0?',\n",
       " 'How do are non-dihydropyridine calcium channel blockers used?',\n",
       " 'How can I cope with my boyfriend being extremely jealous?',\n",
       " 'A governmental organisation is threatening your life. You have five hours to hide. What do you do?',\n",
       " 'What does car mean?',\n",
       " 'Do you have a particular kind of music that you listen to when you are sad?',\n",
       " 'Can I give a reward to my virtual assistants for their efforts?',\n",
       " 'What are the admission requirements in Stanford university for an Indian student?',\n",
       " 'What are some sites on the web that criticise indie films?',\n",
       " 'Which type of questions may asked to a civil engineer in UPSC civil services interview?',\n",
       " 'Are the U.S, sanctions against Iran legal and in good faith?',\n",
       " 'What do you think will happen in Seasons 5 and 6 of The Americans?',\n",
       " 'Why do people think it is okay to ask people online advice about health issues?',\n",
       " 'What are some signs that indicate Trump is trying to turn the United States into an authoritarian state?',\n",
       " 'What are the harsh truths about Africa?',\n",
       " 'How is your experience with husky dogs in India? Can they sustain Indian tropical environment?',\n",
       " 'What are the prerequisites to become an assistant professor?',\n",
       " 'Is it helpful to do mtech with low aggregate in mechanical engineering?',\n",
       " 'Do you, as a Christian, think that Jews should convert to Christianity in order to be saved?',\n",
       " 'Did Augustus get married?',\n",
       " 'Are there any theories about how human memory is stored other than in synapses?',\n",
       " 'Who is paying for the royal family besides the Brits?',\n",
       " 'Is queen Elizabeth related to king henry viii?',\n",
       " 'Why are drain flies common on sewage systems?',\n",
       " 'How long does it take you to process a cow?',\n",
       " 'How do charities become so huge?',\n",
       " \"Why are Europeans so ungrateful for America? They'd be speaking German without us and because we cover their military costs, they can spend more on social safety programs.\",\n",
       " 'Where do I find the class clowns at Harvard?',\n",
       " 'Is there a future for us?',\n",
       " 'Which city in India has a good ecosystem for developing prototypes real fast and real cheap for inventors?',\n",
       " 'Is it worth to study in MBA in tier 3 colleges like TAPMI / BIM / KJ SOMAIYA?',\n",
       " 'What is the lease agreement for Common.com or Ollie.co or Coliving.com?',\n",
       " 'Do companies like TCS, Wipro, Infosys give salary during their training period?',\n",
       " 'What supplements work for growing boobs?',\n",
       " 'Should we be more concerned with whether Carter Page is a Russian spy and why was he working for the Trump campaign?',\n",
       " 'Is there any sense for native English person to immigrate to Germany from Great Britain?',\n",
       " \"Do FL police record any data when they check a citizen's ID without issuance of any citations or infractions?\",\n",
       " 'Do electric cars have gears?',\n",
       " 'How do I live on 20,000 a year?',\n",
       " 'What is an impersonal God?',\n",
       " \"How can I avoid my dog from getting wet when it rains if I can't allow her to come inside and there is no dry area available for her to stay under?\",\n",
       " 'What is the best way to deal with sex withdrawal?',\n",
       " \"Where's WeChat symbol?\",\n",
       " 'Where are the best colleges and why (e.g. free tuition, job opportunities?',\n",
       " 'What is the purpose of the siliceous ooze?',\n",
       " 'How do I sell Pakistan? I need lots of money so I decided to sell Pakistan any one wanna buy?',\n",
       " 'Where are the first 10 employees of Flipkart now?',\n",
       " 'The solar system is not a fixed reference frame in the universe, so are we experiencing any time dilation effects due to its movement?',\n",
       " \"Would thin plated armour with folded leather scales underneath make a good knight's armor?\",\n",
       " 'What are some unique bandeau outfits ideas for teenagers?',\n",
       " 'What the simlarity between computer organization and computer arichtecture?',\n",
       " 'What were the most important 5 causes of the Great Depression?',\n",
       " 'Are you covered by insurance if you die on a roller coaster?',\n",
       " 'How did civic nationalism originate?',\n",
       " 'What other big investment options with less risk are there in India except real estate?',\n",
       " 'What eventuality are you prepared to survive and would such a collapse be worth surviving?',\n",
       " \"Why Can't People change Gender physically the way animals can?\",\n",
       " \"Why do my Gmail passwords keep disappearing? I'm on a Mac, and all my Gmail boxes are in the sidebar along the left. Every so often, I lose connection to my Gmail boxes, and have to reset all the passwords. I access these mail boxes every day.\",\n",
       " 'What do I need to do to become a great electrical engineer?',\n",
       " 'Can weed cause cardiac arrest?',\n",
       " 'Are there any types of tooth-coloured fillings?',\n",
       " 'Why do I think it\\'s good for a country to have more CCTV surveillance and phone surveillance despite \"human rights abuse claim\"?',\n",
       " 'How can I notify one of my tweeter contacts about the fact that his account is possibly hacked, since it likes pornographic content, is it possible to send an anonymous message?',\n",
       " 'Choose your least favorite MCU villain. How would you improve him/her?',\n",
       " 'Why cant Indians stop comparing themselves with much developed countries and start working on building themselves instead?',\n",
       " 'Between Armfeldt, Lewenhaupt and Rehnskiöld, who was the best Swedish general?',\n",
       " 'What do psychopaths think about the fat acceptance movement?',\n",
       " 'How do you know if a guy is just sweet and caring or has feelings for you?',\n",
       " \"Have you ever cheated on someone's test in school?\",\n",
       " 'Which companies in India hire SQL developers?',\n",
       " 'What was the most fun you have ever had in your life?',\n",
       " 'What area is considered to be Western Europe?',\n",
       " 'What is the best laptop for everyday use and some light gaming?',\n",
       " 'Who are bigger the red blood cells or the white blood cells?',\n",
       " 'What is the significant of logarithm in image processing?',\n",
       " 'Which area in Banglore is safest for working women?',\n",
       " 'What is the meaning of nudge in hike?',\n",
       " 'What is the most real thing or idea?',\n",
       " \"What's your penis size? Isn't that funny?\",\n",
       " 'What is the relation between the rotation of earth and changing polarities?',\n",
       " 'What is the difference between active duty and the coast guard?',\n",
       " 'How is Dynamic 365 team at Microsoft IDC Hyderabad?',\n",
       " 'How do I keep my lazyness away?',\n",
       " 'Which posion can kill human in few mintues?',\n",
       " 'How long does a stand-up count take in prison?',\n",
       " 'Why is my dad unnecessarily harsh on me than when compared to my siblings (I am a first-born)?',\n",
       " 'Are all anti-missile systems THAADs?',\n",
       " 'Can we have hybrid bike wheels on a mountain bike frame?',\n",
       " 'How do I win over a married man?',\n",
       " \"What do you think of Donald Trump's new 'real news' program hosted by his daughter-in-law?\",\n",
       " 'How was Buddhism an improvement for women in Hindu cultures?',\n",
       " 'What is the largest state in terms of population?',\n",
       " 'What do liberals think the NRA is? Why do they protest the NRA and feel they are evil?',\n",
       " 'How do grown men look in skinny jeans?',\n",
       " 'What is the best site to learn basic computer?',\n",
       " 'What is the background of the Hammer v. Dagenhart case?',\n",
       " 'Are there British actors who have lost their accents either completely or partially from living in America for so long?',\n",
       " 'What would it take for US homeowners to begin putting solar panels on their roofs en masse?',\n",
       " 'How would I be able to record clips of TV shows and upload them on YouTube? What tool is best to use? And does anyone know how I could do it?',\n",
       " 'How can I treat a watery discharge after 39 weeks pregnant?',\n",
       " 'Do most 11 year olds have bad mums and dads?',\n",
       " 'Apparently cold showers are good for your skin and hair. How often should I take them? Once a day or twice a day?',\n",
       " 'How likely is Facebook going bankruptcy?',\n",
       " 'What is the maximum size possible for a thunderstike?',\n",
       " 'What can be revealed throughout the genome of the platypus?',\n",
       " 'What do you think of the 100% renewable feasibility evaluation by LUT and EWG? Are there any major flaws in this study?',\n",
       " 'Do you really think you could follow through with taking a actual bullet for someone?',\n",
       " 'If you inject within the marked areas on this rat, what would you risk penetrating?',\n",
       " 'If a venomous snake bites a human and that human is sick and that venom can cure that human but also harm it how would you go by proceeding that medical procedure?',\n",
       " 'Why is it important to amplify a signal before sending it to the recipient?',\n",
       " 'What can we do for our society?',\n",
       " 'Why are the lifeguards necessary at any aquatic facility?',\n",
       " 'Does the diameter of a bob affect the pendulum?',\n",
       " \"What's the difference between multiplication and quantitative percentages?\",\n",
       " 'If I delete my Quora account, can I use the same email address to create another one?',\n",
       " 'Is there an intuitive way to understand how Radon–Nikodym derivative is useful?',\n",
       " 'Is South Africa a safe country to visit?',\n",
       " 'What is the best route from Houston to San Francisco if I have one week?',\n",
       " \"What is the structure of white blood cells'?\",\n",
       " \"Why can't we stop religious conversions in India?\",\n",
       " \"I like to start a business or continue my dad's business. Should I do BBA or BBM?\",\n",
       " 'What is the fee for COMEDK MBBS 2017?',\n",
       " \"What is the best motivation you've ever received?\",\n",
       " 'My skin turns dark with any body lotion that I use. Why?',\n",
       " 'Why does my mother call me her favorite when were alone but when we are around my other siblings she says she has no favorites?',\n",
       " \"What is the best way to tackle the situation where I am earning much more than my friends and they look at me with 'expectations'?\",\n",
       " 'Does “t” go silent in ‘it’ll”?',\n",
       " 'Hypothetically, how effective would a mercury filled grenade be at killing enemy combatants?',\n",
       " 'Are the syllabic consonants of the Sanskrit varnamala {ऋ, ॠ, ऌ, ॡ} considered vowels or consonants?',\n",
       " 'Should I buy clothes or a phone?',\n",
       " 'Which government medical college can get with 320 marks in NEET 2017 (SC Category)?',\n",
       " 'What are the articles that come from a famous journals and their content is to compare tow things and the writing model or writing skill is worth learning?',\n",
       " 'What would you do if you had total obedience over all living creatures for one day?',\n",
       " 'How do I select the best dental practice marketing agency for dentists?',\n",
       " 'Who are the best professors at the University of Cambridge?',\n",
       " 'Which is best Jaypee 62 or MIT Pune for CSE?',\n",
       " 'What are some important chapters for NEET 2018 for biology?',\n",
       " 'Do we get foreign assignments in public relations?',\n",
       " 'If Britain revokes Article 50 now, would the value of the pound go up? If yes, by how much?',\n",
       " 'My Apple radio keeps surging whenever I turn on the radio. How can I fix it?',\n",
       " 'Which field of work does India have the least members?',\n",
       " 'What parts of your job are fun?',\n",
       " 'How does a business-major student incorporate an international dimension to his/her undergraduate education?',\n",
       " \"How well would have Ike Ibeabuchi done in boxing if he didn't have his career damaged by legal issues?\",\n",
       " 'Can somebody guide me about purchasing an exercise bike for home? What are some good models in the range of rs. 4000 to 7000 with features?',\n",
       " 'Why do people find pleasure in enemas?',\n",
       " 'Which football should I buy?',\n",
       " 'What were General Walter Bedell \"Beetle\" Smith\\'s major accomplishments?',\n",
       " 'Is Kenya safe foe residents?',\n",
       " 'What are some good examples of suspension in chemistry?',\n",
       " 'How profitable is the car leasing business post GST?',\n",
       " 'What are the best plants for increasing indoor air quality that are easily maintanable?',\n",
       " 'What is the biggest fear of newly retired people?',\n",
       " 'Can we move outside after midnight in Kota just to swing our mood?',\n",
       " 'Which presidents since Kennedy has committed the most crimes?',\n",
       " 'Why do people in Beijing put a traffic cone next to their parked car?',\n",
       " 'What is the experience of an Indian-American going to India for medical school?',\n",
       " 'Does it make sense for a container component to render several presentation components?',\n",
       " 'Why does Ronaldinho looks like a girl?',\n",
       " 'What companies sell non-branded high quality smart casual clothes?',\n",
       " 'Who is the present education minister of Karnataka?',\n",
       " 'In videos of North Korean military parades, they march with what appears to be a very exaggerated goose step. Is this their normal marching step?',\n",
       " 'Who are often unsuccessful to catch their prey?',\n",
       " 'How soon after WWII was a right-wing political party founded in Germany?',\n",
       " 'My boss watched porn on his work computer, how can I get him to stop?',\n",
       " 'What is mostly imortant in being a doctor?',\n",
       " 'How tall do your parents have to be for you to become 6 feet?',\n",
       " 'What steps I should be taking if I am having an idea about a product that can solve the problem that sportsmen face?',\n",
       " 'What are the most effective strategies that startups are using to reach out to target audience other than paid ads and blogs?',\n",
       " 'If the devil really exists, what is currently working on?',\n",
       " 'Why does my grandmother call wrestling \"wrastling\"?',\n",
       " 'Why do I have sudden intrusive thoughts about being in pain?',\n",
       " 'What are some good and unique crochet scarf patterns?',\n",
       " 'Is Brian Griffin a good role model on Family Guy?',\n",
       " 'Frequently, part of my legs starts getting very itchy for no apparent reason and usually there will be an isolated hive/bump or a heat-rash-like condition. Does anyone know what causes this?',\n",
       " 'What is difference between a gene and a allele?',\n",
       " 'What are the uses of face oil? Which face oil is good for dry skin (I have extremely dry skin)?',\n",
       " 'What are cons of surface mining?',\n",
       " 'What are some great places according to you to travel solo?',\n",
       " 'What pleasure is there in keeping snakes as pets?',\n",
       " 'Can you get sick from old water?',\n",
       " 'Has it ever happened that you lost your faith and belief in God?',\n",
       " 'How do I find out the password for my Elite paycheck plus debit card if I haven’t set one up?',\n",
       " 'What are my chances at 1370 MP state rank in NEET?',\n",
       " 'What are your favourite before and after sentences?',\n",
       " 'Since Sasuke and Naruto are the reincarnation of Indra and Ashura, are they brothers?',\n",
       " 'Can I do genetic engineering after doing chemical engineering?',\n",
       " \"Why is it that the phrase 'the dead of night' makes sense, but 'the alive of day' doesn't?\",\n",
       " 'What are the job opportunities after doing MA (economics)?',\n",
       " 'Which player had the greatest performance in Super Bowl 2018?',\n",
       " 'What is something that never needs to be said?',\n",
       " 'What is wrong with BJP in Punjab?',\n",
       " 'Shouldnt there be more women in IPS?',\n",
       " 'Could the president sign an executive order banning the NRA from making campaign contributions at any level?',\n",
       " 'Where can I find abandoned places in Campania, Italy?',\n",
       " 'How does Lyft track who I am after deleting and reinstalling their app?',\n",
       " 'Would you die to save your loved one?',\n",
       " 'Did you by any chance go to a naval school?',\n",
       " 'How many agni 5 missiles do India have?',\n",
       " 'Are Mughals descendants of Genghis Khan?',\n",
       " 'What is the best city you have ever visited in Turkey?',\n",
       " 'What are the best lifehacks for hairs?',\n",
       " 'Will America\\'s current \"civil war\" go hot and if so how will it go?',\n",
       " 'How can I improve my high kick technique?',\n",
       " 'What are the functions of amylose?',\n",
       " 'How much does it cost to build a professional basketball half-court in France?',\n",
       " 'What will happen to Bitcoin when power goes out for weeks across the world from a CME?',\n",
       " 'Are motorcycles in Toronto highways exempt from the speed limit?',\n",
       " 'How can I learn making a stop motion whiteboard video (like the video in the link) and does it take so much time to make one?',\n",
       " 'Today, my friend came up to me at lunch and said “this morning I started my period and I have cramps”. I just went “um I didn’t ask…”. She said that it was weird that I was uncomfortable when she told me. Was my response the correct one to give?',\n",
       " 'What are the parts of a nucleus?',\n",
       " 'A new software developer insisted to use kubernetes for a backend project where no developers in the company have experience in Docker and Kubernetes, as the CTO, what should I do?',\n",
       " 'Dating is boring for me. Am I the only one?',\n",
       " 'How was early Christianity practiced diffferently than today?',\n",
       " 'Why is my stream pixelated and choppy?',\n",
       " 'What would have happened if Indian subcontinent had stayed together?',\n",
       " 'How do I make a girlfriend in Bangalore? I work in IT, have sufficient money, and I am good looking. And No girls at workplace.',\n",
       " 'What are the personal benefits of giving to charity, other than tax breaks?',\n",
       " 'Is there any organisation/club in Pune which helps to appear for the Ham radio licencing (ASOC) examination?',\n",
       " 'Why Chinese people are always not welcome in all countries?',\n",
       " 'Why do clouds look solid from the ground?',\n",
       " 'Is Frieza a man or a woman?',\n",
       " 'Who will win in video game battle: Adam d angelo vs Kim kardasian?',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question_text'].tolist()+test['question_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocess:\n",
      "glove:\n",
      "Found embeddings for 33.024% of vocab\n",
      "Found embeddings for  88.148% of all text\n",
      "para:\n",
      "Found embeddings for 19.541% of vocab\n",
      "Found embeddings for  72.206% of all text\n",
      "Lower done\n",
      "Added 14725 words to embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 68715/1306122 [00:00<00:01, 687147.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 words to embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:01<00:00, 814891.26it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 741222.46it/s]\n",
      "  0%|          | 1616/1306122 [00:00<01:20, 16157.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace quote done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [01:09<00:00, 18840.36it/s]\n",
      "100%|██████████| 56370/56370 [00:02<00:00, 18932.24it/s]\n",
      "  0%|          | 1301/1306122 [00:00<01:40, 13002.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace mapping done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [01:26<00:00, 15176.92it/s]\n",
      "100%|██████████| 56370/56370 [00:03<00:00, 15193.24it/s]\n",
      "  1%|          | 10721/1306122 [00:00<00:12, 107208.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep punc done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:10<00:00, 124877.63it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 124566.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace numbers done\n",
      "After preprocess:\n",
      "glove:\n",
      "Found embeddings for 69.050% of vocab\n",
      "Found embeddings for  99.428% of all text\n",
      "para:\n",
      "Found embeddings for 73.524% of vocab\n",
      "Found embeddings for  99.481% of all text\n"
     ]
    }
   ],
   "source": [
    "# Before preprocess:\n",
    "print(\"Before preprocess:\")\n",
    "vocab = build_vocab(train['question_text'].tolist()+test['question_text'].tolist())\n",
    "print(\"glove:\")\n",
    "oov_glove = check_coverage(vocab, embeddings_index_glove)\n",
    "print(\"para:\")\n",
    "oov_para = check_coverage(vocab, embeddings_index_para)\n",
    "# print(\"fasttext:\")\n",
    "# oov_fasttext = check_coverage(vocab, embeddings_index_fasttext)\n",
    "\n",
    "# Lower\n",
    "train[\"question_text\"] = train[\"question_text\"].str.lower()\n",
    "test[\"question_text\"] = test[\"question_text\"].str.lower()\n",
    "print(\"Lower done\")\n",
    "\n",
    "# Add lower word to embedding:\n",
    "add_lower(embeddings_index_glove, vocab)\n",
    "add_lower(embeddings_index_para, vocab)\n",
    "# add_lower(embeddings_index_fasttext, vocab)\n",
    "\n",
    "# Replace quote\n",
    "train['question_text'] = train['question_text'].progress_apply(lambda x: replace_quote(x))\n",
    "test['question_text'] = test['question_text'].progress_apply(lambda x: replace_quote(x))\n",
    "print(\"Replace quote done\")\n",
    "\n",
    "# Replace mapping(contraction & mispell)\n",
    "train['question_text'] = train['question_text'].progress_apply(lambda x: replace_mapping(x))\n",
    "test['question_text'] = test['question_text'].progress_apply(lambda x: replace_mapping(x))\n",
    "print(\"Replace mapping done\")\n",
    "\n",
    "# Replace punc(效果变差)\n",
    "# train['question_text'] = train['question_text'].progress_apply(lambda x: replace_punc(x))\n",
    "# test['question_text'] = test['question_text'].progress_apply(lambda x: replace_punc(x))\n",
    "# print(\"Replace punc done\")\n",
    "\n",
    "# Sep punc\n",
    "train['question_text'] = train['question_text'].progress_apply(lambda x: sep_punc(x))\n",
    "test['question_text'] = test['question_text'].progress_apply(lambda x: sep_punc(x))\n",
    "print(\"Sep punc done\")\n",
    "\n",
    "# Replace numbers\n",
    "train['question_text'] = train['question_text'].progress_apply(lambda x: replace_numbers(x))\n",
    "test['question_text'] = test['question_text'].progress_apply(lambda x: replace_numbers(x))\n",
    "print(\"Replace numbers done\")\n",
    "\n",
    "# After preprocess:\n",
    "print(\"After preprocess:\")\n",
    "vocab = build_vocab(train['question_text'])\n",
    "print(\"glove:\")\n",
    "oov_glove = check_coverage(vocab, embeddings_index_glove)\n",
    "print(\"para:\")\n",
    "oov_para = check_coverage(vocab, embeddings_index_para)\n",
    "# print(\"fasttext:\")\n",
    "# oov_fasttext = check_coverage(vocab, embeddings_index_fasttext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocess result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"tmp/clean_text.txt\", \"w\", encoding=\"UTF-8\") as f:\n",
    "#     for s in train[\"question_text\"]:\n",
    "#         f.write(s + \"\\n\")\n",
    "# train.to_csv(\"tmp/preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen_word_train: 602\n",
      "maxlen_word_testa: 398\n",
      "avglen_word_train:\n",
      " (14.729379031974043, OrderedDict([(1, 5), (2, 19), (3, 49), (4, 5348), (5, 20390), (6, 39603), (7, 68448), (8, 96094), (9, 113196), (10, 115721), (11, 109959), (12, 96637), (13, 84339), (14, 71963), (15, 61554), (16, 52403), (17, 44853), (18, 38151), (19, 32967), (20, 28461), (21, 24846), (22, 21667), (23, 19106), (24, 17205), (25, 15305), (26, 13820), (27, 12519), (28, 11251), (29, 10161), (30, 8936), (31, 7938), (32, 7033), (33, 6104), (34, 5222), (35, 4489), (36, 4044), (37, 3558), (38, 3167), (39, 2945), (40, 2663), (41, 2433), (42, 2341), (43, 2094), (44, 2042), (45, 1950), (46, 1801), (47, 1601), (48, 1510), (49, 1318), (50, 1162), (51, 989), (52, 872), (53, 796), (54, 607), (55, 519), (56, 441), (57, 333), (58, 249), (59, 200), (60, 152), (61, 125), (62, 65), (63, 52), (64, 41), (65, 36), (66, 36), (67, 21), (68, 9), (69, 13), (70, 14), (71, 11), (72, 10), (73, 7), (74, 13), (75, 9), (76, 10), (77, 4), (78, 11), (79, 2), (80, 4), (81, 3), (82, 4), (83, 2), (84, 5), (85, 4), (86, 2), (87, 2), (88, 2), (89, 3), (90, 1), (91, 4), (92, 6), (93, 2), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (100, 2), (101, 3), (102, 1), (104, 2), (105, 2), (107, 1), (108, 1), (109, 2), (111, 1), (115, 1), (116, 1), (118, 1), (134, 1), (136, 1), (143, 2), (144, 1), (147, 1), (149, 1), (155, 1), (172, 1), (178, 1), (185, 2), (241, 1), (252, 1), (530, 1), (602, 1)]))\n",
      "avglen_word_testa:\n",
      " (14.665424871385488, OrderedDict([(3, 4), (4, 246), (5, 871), (6, 1726), (7, 2928), (8, 4143), (9, 4916), (10, 5036), (11, 4776), (12, 4314), (13, 3617), (14, 3166), (15, 2648), (16, 2113), (17, 2000), (18, 1647), (19, 1387), (20, 1265), (21, 1019), (22, 947), (23, 818), (24, 759), (25, 687), (26, 613), (27, 502), (28, 432), (29, 441), (30, 402), (31, 310), (32, 280), (33, 240), (34, 204), (35, 176), (36, 173), (37, 144), (38, 133), (39, 139), (40, 108), (41, 108), (42, 119), (43, 93), (44, 98), (45, 86), (46, 80), (47, 67), (48, 65), (49, 64), (50, 45), (51, 38), (52, 33), (53, 27), (54, 25), (55, 22), (56, 11), (57, 13), (58, 7), (59, 8), (60, 6), (61, 4), (62, 2), (64, 2), (65, 3), (66, 1), (69, 2), (70, 1), (72, 1), (76, 1), (77, 1), (83, 1), (88, 1), (99, 1), (113, 1), (136, 1), (162, 1), (398, 1)]))\n"
     ]
    }
   ],
   "source": [
    "def get_maxlen(df):\n",
    "    \"\"\"获取训练集单个序列的最大长度\n",
    "    \"\"\"\n",
    "    assert df is not None, \"df can not be None\"\n",
    "    maxlen = 0\n",
    "    for d in df:\n",
    "        maxlen = max(maxlen, len(d.split()))\n",
    "    return maxlen\n",
    "\n",
    "def get_avglen(df):\n",
    "    \"\"\"获取训练集单个序列的平均长度\n",
    "    \"\"\"\n",
    "    assert df is not None, \"df can not be None\"\n",
    "    tmp = [len(d.split()) for d in df]\n",
    "    counter = Counter(tmp)\n",
    "    res = OrderedDict(sorted(counter.items(), key=lambda t: t[0]))\n",
    "    return np.mean(tmp), res\n",
    "\n",
    "# 最大长度 word level\n",
    "print(\"maxlen_word_train:\", get_maxlen(train.question_text))\n",
    "print(\"maxlen_word_testa:\", get_maxlen(test.question_text))\n",
    "# 平均长度 word level\n",
    "print(\"avglen_word_train:\\n\", get_avglen(train.question_text))\n",
    "print(\"avglen_word_testa:\\n\", get_avglen(test.question_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(word_index): 187252\n"
     ]
    }
   ],
   "source": [
    "def load_single_split(val_size=0.1):\n",
    "    train_df, val_df = train_test_split(train, test_size=val_size, random_state=SEED)\n",
    "    X_train = train_df[\"question_text\"].values\n",
    "    X_val = val_df[\"question_text\"].values\n",
    "    T_X = test[\"question_text\"].values\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "    tokenizer.fit_on_texts(list(X_train))\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val = tokenizer.texts_to_sequences(X_val)\n",
    "    T_X = tokenizer.texts_to_sequences(T_X)\n",
    "\n",
    "    X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "    X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "    T_X = pad_sequences(T_X, maxlen=maxlen)\n",
    "\n",
    "    Y_train = train_df['target'].values\n",
    "    Y_val = val_df['target'].values  \n",
    "    \n",
    "    # shuffle\n",
    "    train_idx = np.random.permutation(len(X_train))\n",
    "    val_idx = np.random.permutation(len(X_val))\n",
    "    X_train = X_train[train_idx]\n",
    "    X_val = X_val[val_idx]\n",
    "    Y_train = Y_train[train_idx]\n",
    "    Y_val = Y_val[val_idx]\n",
    "    return X_train, X_val, T_X, Y_train, Y_val, tokenizer.word_index\n",
    "\n",
    "if cv:\n",
    "    X = train[\"question_text\"].fillna(\"_na_\").values\n",
    "    T_X = test[\"question_text\"].fillna(\"_na_\").values\n",
    "    tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "    tokenizer.fit_on_texts(list(X))\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=maxlen)\n",
    "    T_X = tokenizer.texts_to_sequences(T_X)\n",
    "    T_X = pad_sequences(T_X, maxlen=maxlen)\n",
    "    Y = train['target'].values\n",
    "    word_index = tokenizer.word_index\n",
    "    print(\"len(word_index):\", len(word_index))\n",
    "else:\n",
    "    X_train, X_val, T_X, Y_train, Y_val, word_index = load_single_split(val_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# np.save(\"tmp/X\", X)\n",
    "# np.save(\"tmp/Y\", Y)\n",
    "# np.save(\"tmp/T_X\", T_X)\n",
    "# np.save(\"tmp/features\", features)\n",
    "# np.save(\"tmp/test_features\", test_features)\n",
    "# np.save(\"tmp/word_index\", word_index)\n",
    "\n",
    "# load\n",
    "# X = np.load(\"tmp/X.npy\")\n",
    "# Y = np.load(\"tmp/Y.npy\")\n",
    "# T_X = np.load(\"tmp/T_X.npy\")\n",
    "# features = np.load(\"tmp/features.npy\")\n",
    "# test_features = np.load(\"tmp/test_features.npy\")\n",
    "# word_index = np.load(\"tmp/word_index.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def build_emb(embeddings_index, max_features, word_index):\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    emb_size = all_embs.shape[1]\n",
    "\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, emb_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "def build_emb_smart(emb1, emb2, max_features, word_index, emb_size=300):\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "\n",
    "    all_emb1 = np.stack(emb1.values())\n",
    "    emb1_mean, emb1_std = all_emb1.mean(), all_emb1.std()\n",
    "    all_emb2 = np.stack(emb2.values())\n",
    "    emb2_mean, emb2_std = all_emb2.mean(), all_emb2.std()\n",
    "\n",
    "    embedding_matrix1 = np.random.normal(emb1_mean, emb1_std, (nb_words, emb_size))\n",
    "    embedding_matrix2 = np.random.normal(emb2_mean, emb2_std, (nb_words, emb_size))\n",
    "    embedding_matrix = np.mean([embedding_matrix1, embedding_matrix2], axis=0)\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        emb1_vector = emb1.get(word)\n",
    "        emb2_vector = emb2.get(word)\n",
    "        if emb1_vector is not None and emb2_vector is not None:\n",
    "            embedding_matrix[i] = np.mean([emb1_vector, emb2_vector], axis=0)\n",
    "        else:\n",
    "            if emb1_vector is not None:\n",
    "                embedding_matrix[i] = emb1_vector\n",
    "            elif emb2_vector is not None:\n",
    "                embedding_matrix[i] = emb2_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.19 minutes\n",
      "(95000, 300)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "emb_glove = build_emb(embeddings_index_glove, max_features, word_index)\n",
    "emb_para = build_emb(embeddings_index_para, max_features, word_index)\n",
    "# emb_fasttext = build_emb(embeddings_index_fasttext, max_features, word_index)\n",
    "\n",
    "emb = np.mean([emb_glove, emb_para], axis=0)\n",
    "# emb = np.mean([emb_glove, emb_para, emb_fasttext], axis=0)\n",
    "\n",
    "# emb = build_emb_smart(embeddings_index_glove, embeddings_index_para, max_features, word_index)\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(\"Took {:.2f} minutes\".format(total_time))\n",
    "print(np.shape(emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "\n",
    "class JoinAttention(_Merge):\n",
    "    def __init__(self, step_dim, hid_size,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism according to other vector.\n",
    "        Supports Masking.\n",
    "        # Input shape, list of\n",
    "            2D tensor with shape: `(samples, features_1)`.\n",
    "            3D tensor with shape: `(samples, steps, features_2)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            en = LSTM(64, return_sequences=False)(input)\n",
    "            de = LSTM(64, return_sequences=True)(input2)\n",
    "            output = JoinAttention(64, 20)([en, de])\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.hid_size = hid_size\n",
    "        super(JoinAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('A merge layer [JoinAttention] should be called '\n",
    "                             'on a list of inputs.')\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError('A merge layer [JoinAttention] should be called '\n",
    "                             'on a list of 2 inputs. '\n",
    "                             'Got ' + str(len(input_shape)) + ' inputs.')\n",
    "        if len(input_shape[0]) != 2 or len(input_shape[1]) != 3:\n",
    "            raise ValueError('A merge layer [JoinAttention] should be called '\n",
    "                             'on a list of 2 inputs with first ndim 2 and second one ndim 3. '\n",
    "                             'Got ' + str(len(input_shape)) + ' inputs.')\n",
    "\n",
    "        self.W_en1 = self.add_weight((input_shape[0][-1], self.hid_size),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W0'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.W_en2 = self.add_weight((input_shape[1][-1], self.hid_size),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W1'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.W_de = self.add_weight((self.hid_size,),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W2'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "\n",
    "        if self.bias:\n",
    "            self.b_en1 = self.add_weight((self.hid_size,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b0'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.b_en2 = self.add_weight((self.hid_size,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b1'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.b_de = self.add_weight((input_shape[1][1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b2'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b_en1 = None\n",
    "            self.b_en2 = None\n",
    "            self.b_de = None\n",
    "\n",
    "        self._reshape_required = False\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[1][0], input_shape[1][-1]\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        en = inputs[0]\n",
    "        de = inputs[1]\n",
    "        de_shape = K.int_shape(de)\n",
    "        step_dim = de_shape[1]\n",
    "\n",
    "        hid_en = K.dot(en, self.W_en1)\n",
    "        hid_de = K.dot(de, self.W_en2)\n",
    "        if self.bias:\n",
    "            hid_en += self.b_en1\n",
    "            hid_de += self.b_en2\n",
    "        hid = K.tanh(K.expand_dims(hid_en, axis=1) + hid_de)\n",
    "        eij = K.reshape(K.dot(hid, K.reshape(self.W_de, (self.hid_size, 1))), (-1, step_dim))\n",
    "        if self.bias:\n",
    "            eij += self.b_de[:step_dim]\n",
    "\n",
    "        a = K.exp(eij - K.max(eij, axis=-1, keepdims=True))\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask[1], K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = de * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class AttentivePooling(Layer):\n",
    "    def __init__(self, W_regularizer=None, b_regularizer=None, **kwargs):\n",
    "        self.supports_masking = False\n",
    "        # self.mask =mask\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        super(AttentivePooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        n_in = input_shape[2]\n",
    "        n_out = 1\n",
    "        lim = np.sqrt(6. / (n_in + n_out))\n",
    "        # tanh initializer xavier\n",
    "        self.W = K.random_uniform_variable((n_in, n_out), -lim, lim,\n",
    "                                           name='{}_W'.format(self.name))\n",
    "        self.b = K.zeros((n_out,), name='{}_b'.format(self.name))\n",
    "        self.trainable_weights = [self.W, self.b]\n",
    "        self.regularizer = []\n",
    "        if self.W_regularizer is not None:\n",
    "            self.add_loss(self.W_regularizer(self.W))\n",
    "        if self.b_regularizer is not None:\n",
    "            self.add_loss(self.b_regularizer(self.b))\n",
    "        self.build = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "\n",
    "        memory = inputs\n",
    "        print('memory shape', K.int_shape(memory))\n",
    "        gi = K.tanh(K.dot(memory, self.W) + self.b)  # 32 *6 *1\n",
    "        gi = K.sum(gi, axis=-1)  # 32 *6\n",
    "        alfa = K.softmax(gi)\n",
    "        self.alfa = alfa\n",
    "        output = K.sum(memory * K.expand_dims(alfa, axis=-1), axis=1)  # sum(32 *6 *310)\n",
    "        print('output shape', K.int_shape(output))\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = input_shape\n",
    "        shape = list(shape)\n",
    "\n",
    "        return (shape[0], shape[2])\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    " \n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    " \n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    " \n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    " \n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    " \n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    " \n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    " \n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    " \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    " \n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    " \n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    " \n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    " \n",
    "        a = K.exp(ait)\n",
    " \n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    " \n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    " \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "\n",
    "class DropConnect(Wrapper):\n",
    "    def __init__(self, layer, prob=1., **kwargs):\n",
    "        self.prob = prob\n",
    "        self.layer = layer\n",
    "        super(DropConnect, self).__init__(layer, **kwargs)\n",
    "        if 0. < self.prob < 1.:\n",
    "            self.uses_learning_phase = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not self.layer.built:\n",
    "            self.layer.build(input_shape)\n",
    "            self.layer.built = True\n",
    "        super(DropConnect, self).build()\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.layer.compute_output_shape(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        if 0. < self.prob < 1.:\n",
    "            self.layer.kernel = K.in_train_phase(K.dropout(self.layer.kernel, self.prob), self.layer.kernel)\n",
    "            self.layer.bias = K.in_train_phase(K.dropout(self.layer.bias, self.prob), self.layer.bias)\n",
    "        return self.layer.call(x)\n",
    "\n",
    "\n",
    "class TargetedDropout(Layer):\n",
    "    \"\"\"See: https://openreview.net/pdf?id=HkghWScuoQ\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 drop_rate,\n",
    "                 target_rate,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "        :param drop_rate: Dropout rate.\n",
    "        :param target_rate: Targeting proportion.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        super(TargetedDropout, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.drop_rate = drop_rate\n",
    "        self.target_rate = target_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'drop_rate': self.drop_rate,\n",
    "            'target_rate': self.target_rate,\n",
    "        }\n",
    "        base_config = super(TargetedDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def _compute_target_mask(self, inputs, mask=None):\n",
    "        input_shape = K.shape(inputs)\n",
    "        input_type = K.dtype(inputs)\n",
    "        mask_threshold = K.constant(1e8, dtype=input_type)\n",
    "        channel_num = input_shape[-1]\n",
    "        channel_dim = K.prod(input_shape[:-1])\n",
    "        masked_inputs = inputs\n",
    "        if mask is not None:\n",
    "            masked_inputs = K.switch(\n",
    "                K.cast(mask, K.floatx()) > 0.5,\n",
    "                masked_inputs,\n",
    "                K.ones_like(masked_inputs, dtype=input_type) * mask_threshold\n",
    "            )\n",
    "        norm = K.abs(masked_inputs)\n",
    "        channeled_norm = K.transpose(K.reshape(norm, (channel_dim, channel_num)))\n",
    "        weight_num = K.sum(\n",
    "            K.reshape(K.cast(masked_inputs < mask_threshold, K.floatx()), (channel_dim, channel_num)),\n",
    "            axis=0,\n",
    "        )\n",
    "        indices = K.stack(\n",
    "            [\n",
    "                K.arange(channel_num, dtype='int32'),\n",
    "                K.cast(self.target_rate * weight_num, dtype='int32') - 1,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        threshold = -K.tf.gather_nd(K.tf.nn.top_k(-channeled_norm, k=K.max(indices[:, 1]) + 1).values, indices)\n",
    "        threshold = K.reshape(K.tile(threshold, [channel_dim]), input_shape)\n",
    "        target_mask = K.switch(\n",
    "            norm <= threshold,\n",
    "            K.ones_like(inputs, dtype=K.floatx()),\n",
    "            K.zeros_like(inputs, dtype=K.floatx()),\n",
    "        )\n",
    "        return target_mask\n",
    "\n",
    "    def call(self, inputs, mask=None, training=None):\n",
    "        target_mask = self._compute_target_mask(inputs, mask=mask)\n",
    "\n",
    "        def dropped_mask():\n",
    "            drop_mask = K.switch(\n",
    "                K.random_uniform(K.shape(inputs)) < self.drop_rate,\n",
    "                K.ones_like(inputs, K.floatx()),\n",
    "                K.zeros_like(inputs, K.floatx()),\n",
    "            )\n",
    "            return target_mask * drop_mask\n",
    "\n",
    "        def pruned_mask():\n",
    "            return target_mask\n",
    "\n",
    "        mask = K.in_train_phase(dropped_mask, pruned_mask, training=training)\n",
    "        outputs = K.switch(\n",
    "            mask > 0.5,\n",
    "            K.zeros_like(inputs, dtype=K.dtype(inputs)),\n",
    "            inputs,\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DotProdSelfAttention(Layer):\n",
    "    \"\"\"The self-attention layer as in 'Attention is all you need'.\n",
    "    paper reference: https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, units,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(DotProdSelfAttention, self).__init__(*kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        input_dim = input_shape[-1]\n",
    "        # We assume the output-dim of Q, K, V are the same\n",
    "        self.kernels = dict.fromkeys(['Q', 'K', 'V'])\n",
    "        for key, _ in self.kernels.items():\n",
    "            self.kernels[key] = self.add_weight(shape=(input_dim, self.units),\n",
    "                                                initializer=self.kernel_initializer,\n",
    "                                                name='kernel_{}'.format(key),\n",
    "                                                regularizer=self.kernel_regularizer,\n",
    "                                                constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            raise NotImplementedError\n",
    "        super(DotProdSelfAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        Q = K.dot(x, self.kernels['Q'])\n",
    "        K_mat = K.dot(x, self.kernels['K'])\n",
    "        V = K.dot(x, self.kernels['V'])\n",
    "        attention = K.batch_dot(Q, K.permute_dimensions(K_mat, [0, 2, 1]))\n",
    "        d_k = K.constant(self.units, dtype=K.floatx())\n",
    "        attention = attention / K.sqrt(d_k)\n",
    "        attention = K.batch_dot(K.softmax(attention, axis=-1), V)\n",
    "        return attention\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        assert input_shape[-1]\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "\n",
    "def encoder(input_tensor, emb_size, n_heads=4):\n",
    "    \"\"\"One encoder as in Attention Is All You Need\n",
    "    \"\"\"\n",
    "    # Sub-layer 1\n",
    "    # Multi-Head Attention\n",
    "    multiheads = []\n",
    "    d_v = emb_size // n_heads\n",
    "    for i in range(n_heads):\n",
    "        multiheads.append(DotProdSelfAttention(d_v)(input_tensor))\n",
    "    multiheads = concatenate(multiheads, axis=-1)\n",
    "    multiheads = Dense(emb_size)(multiheads)\n",
    "    multiheads = Dropout(0.1)(multiheads)\n",
    "    \n",
    "    # Residual Connection\n",
    "    res_con = add([input_tensor, multiheads])\n",
    "    # Didn't use layer normalization, use Batch Normalization instead here\n",
    "    res_con = BatchNormalization(axis=-1)(res_con)\n",
    "    \n",
    "    # Sub-layer 2\n",
    "    # 2 Feed forward layer\n",
    "    ff1 = Dense(64, activation='relu')(res_con)\n",
    "    ff2 = Dense(emb_size)(ff1)\n",
    "    output = add([res_con, ff2])\n",
    "    output = BatchNormalization(axis=-1)(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def positional_signal(hidden_size: int, length: int, min_timescale: float=1.0, max_timescale: float=1e4):\n",
    "    \"\"\"\n",
    "    Helper function, constructing basic positional encoding.\n",
    "    The code is partially based on implementation from Tensor2Tensor library\n",
    "    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n",
    "    \"\"\"\n",
    "    if hidden_size % 2 != 0:\n",
    "        raise ValueError(\n",
    "            f\"The hidden dimension of the model must be divisible by 2.\"\n",
    "            f\"Currently it is {hidden_size}\")\n",
    "    position = K.arange(0, length, dtype=K.floatx())\n",
    "    num_timescales = hidden_size // 2\n",
    "    log_timescale_increment = K.constant(\n",
    "        (np.log(float(max_timescale) / float(min_timescale)) / (num_timescales - 1)),\n",
    "        dtype=K.floatx())\n",
    "    inv_timescales = (min_timescale * K.exp(K.arange(num_timescales, dtype=K.floatx()) * -log_timescale_increment))\n",
    "    scaled_time = K.expand_dims(position, 1) * K.expand_dims(inv_timescales, 0)\n",
    "    signal = K.concatenate([K.sin(scaled_time), K.cos(scaled_time)], axis=1)\n",
    "    return K.expand_dims(signal, axis=0)\n",
    "\n",
    "\n",
    "class AddPositionalEncoding(Layer):\n",
    "    \"\"\"\n",
    "    Injects positional encoding signal described in section 3.5 of the original\n",
    "    paper \"Attention is all you need\". Also a base class for more complex\n",
    "    coordinate encoding described in \"Universal Transformers\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_timescale: float=1.0, max_timescale: float=1.0e4, **kwargs):\n",
    "        self.min_timescale = min_timescale\n",
    "        self.max_timescale = max_timescale\n",
    "        self.signal = None\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['min_timescale'] = self.min_timescale\n",
    "        config['max_timescale'] = self.max_timescale\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, length, hidden_size = input_shape\n",
    "        self.signal = positional_signal(\n",
    "            hidden_size, length, self.min_timescale, self.max_timescale)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs + self.signal\n",
    "\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], (input_shape[2] * self.k))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0]\n",
    "\n",
    "        # return flattened output\n",
    "        return Flatten()(top_k)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'k': self.k}\n",
    "        base_config = super(KMaxPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class SeqSelfAttention(Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e10)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.matrix_band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.matrix_band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqSelfAttention': SeqSelfAttention}\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_smart(y_true, y_pred):\n",
    "    args = np.argsort(y_pred)\n",
    "    tp = y_true.sum()\n",
    "    fs = (tp - np.cumsum(y_true[args[:-1]])) / np.arange(y_true.shape[0] + tp - 1, tp, -1)\n",
    "    res_idx = np.argmax(fs)\n",
    "    return 2 * fs[res_idx], (y_pred[args[res_idx]] + y_pred[args[res_idx + 1]]) / 2\n",
    "\n",
    "def threshold_search(y_true, y_pred):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in [i * 0.01 for i in range(100)]:\n",
    "        score = f1_score(y_true=y_true, y_pred=(y_pred > threshold).astype(int))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    return best_score, best_threshold\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_size=1024):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.max_score = 0\n",
    "        self.not_better_count = 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, batch_size=self.batch_size, verbose=2)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            if (score > self.max_score):\n",
    "                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n",
    "                model.save_weights(\"best_weights.h5\")\n",
    "                self.max_score=score\n",
    "                self.not_better_count = 0\n",
    "            else:\n",
    "                self.not_better_count += 1\n",
    "                if self.not_better_count > 3:\n",
    "                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n",
    "                    self.model.stop_training = True\n",
    "\n",
    "\n",
    "def as_keras_metric(method):\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "        \n",
    "class WarmUp(Callback):\n",
    "    def __init__(self):\n",
    "        self.num_passed_batchs = 0\n",
    "        self.warmup_epochs = 1\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # params 是模型自动传递给 Callback 的一些参数\n",
    "        if self.params['steps'] == None:\n",
    "            self.steps_per_epoch = np.ceil(1. * self.params['samples'] / self.params['batch_size'])\n",
    "        else:\n",
    "            self.steps_per_epoch = self.params['steps']\n",
    "        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n",
    "            # 前 1 个 epoch 中，学习率线性地从 0 增加到 0.001\n",
    "            K.set_value(self.model.optimizer.lr,\n",
    "                        0.001 * (self.num_passed_batchs + 1) / self.steps_per_epoch / self.warmup_epochs)\n",
    "            self.num_passed_batchs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamW(Optimizer):\n",
    "    \"\"\"Adam optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Decoupled weight decay over each update.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n",
    "                 epsilon=1e-8, decay=0., **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.init_lr = lr # decoupled weight decay (2/6)\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd # decoupled weight decay (4/6)\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.wd)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class SGDW(Optimizer):\n",
    "    \"\"\"Stochastic gradient descent optimizer.\n",
    "    Includes support for momentum,\n",
    "    learning rate decay, and Nesterov momentum.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        momentum: float >= 0. Parameter updates momentum.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "        weight_decay: float >= 0. Decoupled weight decay over each update.\n",
    "    # References\n",
    "        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01, momentum=0., decay=0., weight_decay=1e-4, # decoupled weight decay (1/6)\n",
    "                 nesterov=False, **kwargs):\n",
    "        super(SGDW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.init_lr = lr # decoupled weight decay (2/6)\n",
    "            self.momentum = K.variable(momentum, name='momentum')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n",
    "        self.initial_decay = decay\n",
    "        self.nesterov = nesterov\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd  # decoupled weight decay (4/6)\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n",
    "        \n",
    "        # momentum\n",
    "        shapes = [K.int_shape(p) for p in params]\n",
    "        moments = [K.zeros(shape) for shape in shapes]\n",
    "        self.weights = [self.iterations] + moments\n",
    "        for p, g, m in zip(params, grads, moments):\n",
    "            v = self.momentum * m - lr * g  # velocity\n",
    "            self.updates.append(K.update(m, v))\n",
    "\n",
    "            if self.nesterov:\n",
    "                new_p = p + self.momentum * v - lr * g  - eta_t * wd * p  # decoupled weight decay (6/6)\n",
    "            else:\n",
    "                new_p = p + v - lr * wd * p # decoupled weight decay\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'momentum': float(K.get_value(self.momentum)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'nesterov': self.nesterov}\n",
    "        base_config = super(SGDW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruCapsule():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x_emb = Embedding(max_features,\n",
    "                          embedding_matrix.shape[1],\n",
    "                          weights=[embedding_matrix],\n",
    "                          trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(80,\n",
    "                                   return_sequences=True,\n",
    "                                   kernel_initializer=glorot_normal(seed=2018),\n",
    "                                   recurrent_initializer=orthogonal(gain=1.0, seed=2018)\n",
    "                                  ))(x)\n",
    "        \n",
    "        x = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation='relu', kernel_initializer=glorot_normal(seed=2018))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "        \n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class GCDC():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp_seq = Input(shape=(maxlen,), name='seq')\n",
    "        inp_feature = Input(shape=(len(feature_cols),), name='feature')\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp_seq)\n",
    "        x = SpatialDropout1D(0.2)(x)\n",
    "        x = Bidirectional(CuDNNLSTM(96, \n",
    "                                    return_sequences=True, \n",
    "                                    kernel_initializer=glorot_normal(seed=2018), \n",
    "                                    recurrent_initializer=orthogonal(gain=1.0, seed=2018)))(x)\n",
    "\n",
    "        x_1 = Attention(maxlen)(x)\n",
    "        # x_1 = DropConnect(Dense(32, activation=\"relu\", kernel_initializer=glorot_normal(seed=SEED)), prob=0.1)(x_1)\n",
    "\n",
    "        x_2 = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "        x_2 = Flatten()(x_2)\n",
    "        # x_2 = DropConnect(Dense(32, activation=\"relu\", kernel_initializer=glorot_normal(seed=SEED)), prob=0.1)(x_2)\n",
    "\n",
    "        # x_3 = DropConnect(Dense(32, activation=\"relu\", kernel_initializer=glorot_normal(seed=SEED)), prob=0.1)(inp_feature)\n",
    "        # x = concatenate([x_1, x_2, x_3])\n",
    "        \n",
    "        x = concatenate([x_1, x_2, inp_feature])\n",
    "        x = Dense(32, activation='relu', kernel_initializer=glorot_normal(seed=SEED))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=[inp_seq, inp_feature], outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class StackLstm():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Bidirectional(CuDNNLSTM(16, return_sequences=False))(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class StackGru():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)  \n",
    "        x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Bidirectional(CuDNNGRU(32, return_sequences=True))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Bidirectional(CuDNNGRU(16, return_sequences=False))(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class CNN2D():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        filter_sizes = [1,2,3,5]\n",
    "        num_filters = 36\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix])(inp)\n",
    "        x = Reshape((maxlen, emb_size, 1))(x_emb)\n",
    "        max_pool = []\n",
    "        avg_pool = []\n",
    "        attn = []\n",
    "        for i in range(len(filter_sizes)):\n",
    "            conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], emb_size),\n",
    "                                         kernel_initializer='he_normal', activation='elu')(x)\n",
    "            max_pool.append(MaxPooling2D(pool_size=(maxlen - filter_sizes[i] + 1, 1))(conv))\n",
    "        z = Concatenate(axis=1)(max_pool)\n",
    "        z = Flatten()(z)\n",
    "        z = Dropout(0.1)(z)\n",
    "        output = Dense(1, activation=\"sigmoid\")(z)\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class LstmEAtn():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        y = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "\n",
    "        atn_1 = AttentionWithContext()(x)\n",
    "        atn_2 = AttentionWithContext()(y)\n",
    "        atn_pool = AttentivePooling()(y)\n",
    "        avg_pool = GlobalAveragePooling1D()(y)\n",
    "        max_pool = GlobalMaxPooling1D()(y)\n",
    "        x = concatenate([atn_1, atn_2, atn_pool, avg_pool, max_pool])\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)    \n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class TDLstmAtn():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        y = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "\n",
    "        atn_1 = Attention(maxlen)(x)\n",
    "        atn_2 = Attention(maxlen)(y)\n",
    "        avg_pool = GlobalAveragePooling1D()(y)\n",
    "        max_pool = GlobalMaxPooling1D()(y)\n",
    "\n",
    "        x = concatenate([atn_1, atn_2, avg_pool, max_pool])\n",
    "        x = TargetedDropout(drop_rate=0.5, target_rate=0.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(32, activation=\"relu\", kernel_initializer=glorot_normal(seed=SEED))(x)\n",
    "        x = TargetedDropout(drop_rate=0.5, target_rate=0.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)    \n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class PRNN():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        y = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "\n",
    "        last = Lambda(lambda t: t[:, -1])(x)\n",
    "        atten_1 = Attention(maxlen)(x)\n",
    "        atten_2 = Attention(maxlen)(y)\n",
    "        max_pool = GlobalMaxPooling1D()(y)\n",
    "        avg_pool = GlobalAveragePooling1D()(y)\n",
    "        x = concatenate([last, atten_1, atten_2, avg_pool, max_pool], axis=1)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class Transformer():\n",
    "    def model(self, embedding_matrix, maxlen, max_features, n_encoder=1):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        # Add positional encoding\n",
    "        x = AddPositionalEncoding()(x_emb)\n",
    "        for i in range(n_encoder):\n",
    "            x = encoder(x, emb_size)\n",
    "\n",
    "        x = concatenate([x_emb, x])\n",
    "        x = SpatialDropout1D(0.2)(x)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        atn = Attention(maxlen)(x)\n",
    "        avg_pool = GlobalAveragePooling1D()(x)\n",
    "        max_pool = GlobalMaxPooling1D()(x)\n",
    "        x = concatenate([atn, avg_pool, max_pool])\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class LstmCNN():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,), dtype='int32')\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        conv_filters = 32\n",
    "        x = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Reshape((2 * maxlen, 64, 1))(x)\n",
    "        x = Conv2D(conv_filters, (3, 3))(x)\n",
    "        x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "        x = Flatten()(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class HybridCnnGru():\n",
    "    def model(self, emb, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x_emb = Embedding(max_features,\n",
    "                        emb.shape[1],\n",
    "                        weights=[emb],\n",
    "                        trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "\n",
    "        x_gru = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "        x_gru_capsule = Capsule(num_capsule=5, dim_capsule=5, routings=4,\n",
    "                          share_weights=True)(x_gru)\n",
    "        x_gru_capsule = Flatten()(x_gru_capsule)\n",
    "        x_gru_attention = Attention(maxlen)(x_gru)\n",
    "        x_gru_conc = Concatenate()([x_gru_capsule, x_gru_attention])\n",
    "\n",
    "        x_conv_1 = Conv1D(64, kernel_size=1, strides=1, padding=\"same\", kernel_initializer=\"he_uniform\")(x)\n",
    "        x_conv_2 = Conv1D(64, kernel_size=2, strides=1, padding=\"same\", kernel_initializer=\"he_uniform\")(x)\n",
    "        x_conv_3 = Conv1D(64, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_uniform\")(x)\n",
    "        x_conv_5 = Conv1D(64, kernel_size=5, strides=1, padding=\"same\", kernel_initializer=\"he_uniform\")(x)\n",
    "\n",
    "        x_conv = Concatenate()([x_conv_1, x_conv_2, x_conv_3, x_conv_5])\n",
    "        x_conv_capsule = Capsule(num_capsule=5, dim_capsule=5, routings=4,\n",
    "                          share_weights=True)(x_conv)\n",
    "        x_conv_capsule = Flatten()(x_conv_capsule)\n",
    "        x_conv_attention = Attention(maxlen)(x_conv)\n",
    "        x_conv_conc = Concatenate()([x_conv_capsule, x_conv_attention])\n",
    "\n",
    "        x = Concatenate()([x_conv_conc, x_gru_conc])\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(32)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = PReLU()(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(32)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = PReLU()(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class LstmAtn():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        y = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "\n",
    "        atn_1 = Attention(maxlen)(x)\n",
    "        atn_2 = Attention(maxlen)(y)\n",
    "        avg_pool = GlobalAveragePooling1D()(y)\n",
    "        max_pool = GlobalMaxPooling1D()(y)\n",
    "\n",
    "        x = concatenate([atn_1, atn_2, avg_pool, max_pool])\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)    \n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "class LstmFAtn():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp_seq = Input(shape=(maxlen,), name='seq')\n",
    "        inp_feature = Input(shape=(len(feature_cols),), name='feature')\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp_seq)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        y = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "\n",
    "        atn_1 = Attention(maxlen)(x)\n",
    "        atn_2 = Attention(maxlen)(y)\n",
    "        avg_pool = GlobalAveragePooling1D()(y)\n",
    "        max_pool = GlobalMaxPooling1D()(y)\n",
    "        x = concatenate([atn_1, atn_2, avg_pool, max_pool, inp_feature])\n",
    "        x = DropConnect(Dense(32, activation=\"relu\", kernel_initializer=glorot_normal(seed=SEED)), prob=0.2)(x)\n",
    "#         x = Dense(32, activation='relu', kernel_initializer=glorot_normal(seed=SEED))(x)\n",
    "#         x = Dropout(0.1)(x)\n",
    "\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=[inp_seq, inp_feature], outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        # model.compile(loss=[focal_loss(alpha=.25, gamma=2)], optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class LstmAtnContext():\n",
    "    def model(self, embedding_matrix, maxlen, max_features):\n",
    "        inp_seq = Input(shape=(maxlen,), name='seq')\n",
    "        inp_feature = Input(shape=(len(feature_cols),), name='feature')\n",
    "        emb_size = embedding_matrix.shape[1]\n",
    "        x_emb = Embedding(max_features, emb_size, weights=[embedding_matrix], trainable=False)(inp_seq)\n",
    "        x = SpatialDropout1D(0.2)(x_emb)\n",
    "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        y = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "\n",
    "        atn_1 = AttentionWithContext()(x)\n",
    "        atn_2 = AttentionWithContext()(y)\n",
    "        avg_pool = GlobalAveragePooling1D()(y)\n",
    "        max_pool = GlobalMaxPooling1D()(y)\n",
    "\n",
    "        x = concatenate([atn_1, atn_2, avg_pool, max_pool, inp_feature])\n",
    "        x = Dense(32, activation='relu', kernel_initializer=glorot_normal(seed=SEED))(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        output = Dense(1, activation=\"sigmoid\")(x)    \n",
    "\n",
    "        model = Model(inputs=[inp_seq, inp_feature], outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "\n",
    "class MM():\n",
    "    def model(self, models, maxlen):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        outputs = []\n",
    "        for m in models:\n",
    "            y = m(inp)\n",
    "            outputs.append(y)\n",
    "        output = Average()(outputs)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = CyclicLR(base_lr=0.001, max_lr=0.002, step_size=300., mode='exp_range', gamma=0.99994)\n",
    "warmup = False\n",
    "save_best_only = False\n",
    "feature_input = True\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq (InputLayer)                (None, 72)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 72, 300)      28500000    seq[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 72, 300)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 72, 128)      187392      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 72, 128)      74496       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 128)          200         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          200         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "feature (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 523)          0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 feature[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "drop_connect_1 (DropConnect)    (None, 32)           16768       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          drop_connect_1[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 28,779,089\n",
      "Trainable params: 279,089\n",
      "Non-trainable params: 28,500,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/5\n",
      " - 93s - loss: 0.1217 - val_loss: 0.1062\n",
      "\n",
      "Epoch 00001: saving model to model_01.hdf5\n",
      "Epoch 2/5\n",
      " - 91s - loss: 0.1046 - val_loss: 0.1021\n",
      "\n",
      "Epoch 00002: saving model to model_02.hdf5\n",
      "Epoch 3/5\n",
      " - 92s - loss: 0.0988 - val_loss: 0.0985\n",
      "\n",
      "Epoch 00003: saving model to model_03.hdf5\n",
      "Epoch 4/5\n",
      " - 92s - loss: 0.0947 - val_loss: 0.0961\n",
      "\n",
      "Epoch 00004: saving model to model_04.hdf5\n",
      "Epoch 5/5\n",
      " - 92s - loss: 0.0910 - val_loss: 0.0963\n",
      "\n",
      "Epoch 00005: saving model to model_05.hdf5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Optimal F1: 0.6917 at threshold: 0.3578\n",
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/5\n",
      " - 92s - loss: 0.1210 - val_loss: 0.1059\n",
      "\n",
      "Epoch 00001: saving model to model_01.hdf5\n",
      "Epoch 2/5\n",
      " - 91s - loss: 0.1041 - val_loss: 0.1014\n",
      "\n",
      "Epoch 00002: saving model to model_02.hdf5\n",
      "Epoch 3/5\n",
      " - 91s - loss: 0.0982 - val_loss: 0.0975\n",
      "\n",
      "Epoch 00003: saving model to model_03.hdf5\n",
      "Epoch 4/5\n",
      " - 91s - loss: 0.0944 - val_loss: 0.0958\n",
      "\n",
      "Epoch 00004: saving model to model_04.hdf5\n",
      "Epoch 5/5\n",
      " - 91s - loss: 0.0907 - val_loss: 0.0968\n",
      "\n",
      "Epoch 00005: saving model to model_05.hdf5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Optimal F1: 0.6944 at threshold: 0.3838\n",
      "Train on 1044898 samples, validate on 261224 samples\n",
      "Epoch 1/5\n",
      " - 93s - loss: 0.1213 - val_loss: 0.1040\n",
      "\n",
      "Epoch 00001: saving model to model_01.hdf5\n",
      "Epoch 2/5\n",
      " - 91s - loss: 0.1040 - val_loss: 0.0988\n",
      "\n",
      "Epoch 00002: saving model to model_02.hdf5\n",
      "Epoch 3/5\n",
      " - 91s - loss: 0.0984 - val_loss: 0.0965\n",
      "\n",
      "Epoch 00003: saving model to model_03.hdf5\n",
      "Epoch 4/5\n",
      " - 92s - loss: 0.0944 - val_loss: 0.0979\n",
      "\n",
      "Epoch 00004: saving model to model_04.hdf5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/5\n",
      " - 92s - loss: 0.0887 - val_loss: 0.0952\n",
      "\n",
      "Epoch 00005: saving model to model_05.hdf5\n",
      "Optimal F1: 0.6965 at threshold: 0.4258\n",
      "Train on 1044898 samples, validate on 261224 samples\n",
      "Epoch 1/5\n",
      " - 93s - loss: 0.1203 - val_loss: 0.1054\n",
      "\n",
      "Epoch 00001: saving model to model_01.hdf5\n",
      "Epoch 2/5\n",
      " - 91s - loss: 0.1039 - val_loss: 0.0986\n",
      "\n",
      "Epoch 00002: saving model to model_02.hdf5\n",
      "Epoch 3/5\n",
      " - 90s - loss: 0.0984 - val_loss: 0.0966\n",
      "\n",
      "Epoch 00003: saving model to model_03.hdf5\n",
      "Epoch 4/5\n",
      " - 90s - loss: 0.0943 - val_loss: 0.0959\n",
      "\n",
      "Epoch 00004: saving model to model_04.hdf5\n",
      "Epoch 5/5\n",
      " - 91s - loss: 0.0910 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00005: saving model to model_05.hdf5\n",
      "Optimal F1: 0.6941 at threshold: 0.3569\n",
      "Train on 1044898 samples, validate on 261224 samples\n",
      "Epoch 1/5\n",
      " - 93s - loss: 0.1223 - val_loss: 0.1070\n",
      "\n",
      "Epoch 00001: saving model to model_01.hdf5\n",
      "Epoch 2/5\n",
      " - 91s - loss: 0.1041 - val_loss: 0.1013\n",
      "\n",
      "Epoch 00002: saving model to model_02.hdf5\n",
      "Epoch 3/5\n",
      " - 92s - loss: 0.0987 - val_loss: 0.0983\n",
      "\n",
      "Epoch 00003: saving model to model_03.hdf5\n",
      "Epoch 4/5\n",
      " - 92s - loss: 0.0948 - val_loss: 0.0969\n",
      "\n",
      "Epoch 00004: saving model to model_04.hdf5\n",
      "Epoch 5/5\n",
      " - 92s - loss: 0.0911 - val_loss: 0.0961\n",
      "\n",
      "Epoch 00005: saving model to model_05.hdf5\n",
      "Optimal F1: 0.6881 at threshold: 0.3773\n",
      "Optimal F1: 0.6919 at threshold: 0.3802\n",
      "mean_thresh: 0.3803 and mean_loss: 0.0956\n"
     ]
    }
   ],
   "source": [
    "def train_pred(model, epochs, X_train, X_val, T_X, Y_train, Y_val, mm=False):\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=0.0001, verbose=2)\n",
    "    roc_auc = RocAucEvaluation(validation_data=(X_val, Y_val), interval=1, batch_size=1024)\n",
    "    # tensorboard --logdir=./log/run\n",
    "    tb = TensorBoard(log_dir='./log/run')\n",
    "    if save_best_only:\n",
    "        filepath = \"best_weights.h5\"\n",
    "        logloss = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
    "    else:\n",
    "        filepath = \"model_{epoch:02d}.hdf5\"\n",
    "        logloss = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_weights_only=True)\n",
    "    if warmup:\n",
    "        warm_up = WarmUp()\n",
    "        callbacks = [logloss, warm_up, reduce_lr, tb]\n",
    "        # callbacks = [roc_auc, warm_up, reduce_lr, tb]\n",
    "    else:\n",
    "        callbacks = [logloss, reduce_lr, tb]\n",
    "        # callbacks = [roc_auc, reduce_lr, tb]\n",
    "\n",
    "    history = model.fit(X_train, Y_train, batch_size=512, epochs=epochs, validation_data=(X_val, Y_val), verbose=2, callbacks=callbacks)\n",
    "    best_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "    if save_best_only:\n",
    "        model.load_weights(filepath)\n",
    "        pred_val_y = np.squeeze(model.predict(X_val, batch_size=1024, verbose=2))\n",
    "        pred_test_y = np.squeeze(model.predict(T_X, batch_size=1024, verbose=2))\n",
    "    else:\n",
    "        model.load_weights(f'model_0{epochs-1}.hdf5')\n",
    "        y_pred1 = np.squeeze(model.predict(X_val, batch_size=1024, verbose=2))\n",
    "        y_test1 = np.squeeze(model.predict(T_X, batch_size=1024, verbose=2))\n",
    "        model.load_weights(f'model_0{epochs}.hdf5')\n",
    "        y_pred2 = np.squeeze(model.predict(X_val, batch_size=1024, verbose=2))\n",
    "        y_test2 = np.squeeze(model.predict(T_X, batch_size=1024, verbose=2))\n",
    "        pred_val_y = (y_pred1 + y_pred2) / 2\n",
    "        pred_test_y = (y_test1 + y_test2) / 2\n",
    "\n",
    "    best_score, best_thresh = f1_smart(Y_val, pred_val_y)\n",
    "    # best_score, best_thresh = threshold_search(Y_val, pred_val_y)\n",
    "    print('Optimal F1: {:.4f} at threshold: {:.4f}'.format(best_score, best_thresh))\n",
    "    if mm:\n",
    "        models.append(model)\n",
    "    else:\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "    return pred_val_y, pred_test_y, best_score, best_thresh, best_loss\n",
    "\n",
    "def train_single(m, emb, epochs, name):\n",
    "    print('\\n', name)\n",
    "    model = m().model(emb, maxlen, max_features)\n",
    "    pred_val_y, pred_test_y, best_score, best_thresh, best_loss = train_pred(model, epochs, X_train, X_val, T_X, Y_train, Y_val)\n",
    "    return [pred_val_y, pred_test_y, best_score, best_thresh, best_loss, name]\n",
    "\n",
    "def train_mm(m, emb, epochs, name):\n",
    "    print('\\n', name)\n",
    "    model = m().model(emb, maxlen, max_features)\n",
    "    train_pred(model, epochs, X_train, X_val, T_X, Y_train, Y_val, mm=True)\n",
    "\n",
    "if cv:\n",
    "    kfolds, epochs = 5, 5\n",
    "    run = 5\n",
    "    kf = StratifiedKFold(n_splits=kfolds, random_state=26, shuffle=True).split(X, Y)\n",
    "    loss = []\n",
    "    thresh = []\n",
    "    train_meta = np.zeros(Y.shape)\n",
    "    test_meta = np.zeros(T_X.shape[0])\n",
    "    if feature_input:\n",
    "        x_test = [T_X, test_features]\n",
    "    else:\n",
    "        x_test = T_X\n",
    "\n",
    "    for i, (train_idx, valid_idx) in enumerate(kf):\n",
    "        X_train, X_val, Y_train, Y_val = X[train_idx], X[valid_idx], Y[train_idx], Y[valid_idx]\n",
    "        if feature_input:\n",
    "            features_train = features[train_idx]\n",
    "            features_val= features[valid_idx]\n",
    "            x_train = [X_train, features_train]\n",
    "            x_val = [X_val, features_val]\n",
    "        else:\n",
    "            x_train = X_train\n",
    "            x_val = X_val\n",
    "\n",
    "        model = LstmFAtn().model(emb, maxlen, max_features)\n",
    "        if i == 0: print(model.summary())\n",
    "        pred_val_y, pred_test_y, best_score, best_thresh, best_loss = train_pred(model, epochs, x_train, x_val, x_test, Y_train, Y_val)\n",
    "        loss.append(best_loss)\n",
    "        thresh.append(best_thresh)\n",
    "        train_meta[valid_idx] = pred_val_y\n",
    "        test_meta += pred_test_y / run\n",
    "        if i == run - 1:\n",
    "            break\n",
    "    \n",
    "    if run == kfolds:\n",
    "        best_score, best_thresh = f1_smart(np.squeeze(Y), train_meta)\n",
    "        # best_score, best_thresh = threshold_search(np.squeeze(Y), train_meta)\n",
    "        print('Optimal F1: {:.4f} at threshold: {:.4f}'.format(best_score, best_thresh))\n",
    "    else:\n",
    "        threshold = np.mean(thresh)\n",
    "    print('mean_thresh: {:.4f} and mean_loss: {:.4f}'.format(np.mean(thresh), np.mean(loss)))\n",
    "    test_meta = test_meta.reshape((-1, 1))\n",
    "    pred_test_y = (test_meta > best_thresh).astype(int)\n",
    "else:\n",
    "    train_conf = [\n",
    "        [LstmAtn, emb, 4, 'LstmAtn_emb_mean'],\n",
    "        [PRNN, emb, 4, 'PRNN_emb_mean'],\n",
    "        [LstmAtn, emb_glove, 4, 'LstmAtn_emb_glove'],\n",
    "        [LstmEAtn, emb, 4, 'LstmEAtn_emb_mean'],\n",
    "        [StackLstm, emb, 4, 'StackLstm_emb_mean'],\n",
    "    #     [GCDC, emb, 5, 'GCDC_emb_mean'],\n",
    "    #     [GruCapsule, emb, 5, 'GruCapsule_emb_mean'],\n",
    "    ]\n",
    "    \n",
    "    #     # 根据10次平均值决定模型权重\n",
    "    #     scores, losses = [], []\n",
    "    #     for i in range(10):\n",
    "    #         outputs = []\n",
    "    #         for item in train_conf:\n",
    "    #             outputs.append(train_single(*item))\n",
    "    #         score = [output[2] for output in outputs]\n",
    "    #         loss = [output[4] for output in outputs]\n",
    "    #         print(score, loss)\n",
    "    #         scores.append(score)\n",
    "    #         losses.append(loss)\n",
    "    #     score = np.mean(scores, axis=0)\n",
    "    #     loss = np.mean(losses, axis=0)\n",
    "    #     print(score, loss)\n",
    "\n",
    "    ensemble_w = True\n",
    "    weights = [0.3, 0.2, 0.2, 0.15, 0.15]\n",
    "    outputs = []\n",
    "    for item in train_conf:\n",
    "        outputs.append(train_single(*item))\n",
    "\n",
    "    if ensemble_w:\n",
    "        y_pred = np.sum([outputs[i][0] * weights[i] for i in range(len(outputs))], axis=0)\n",
    "        test_pred = np.sum([outputs[i][1] * weights[i] for i in range(len(outputs))], axis=0)\n",
    "    else:\n",
    "        y_pred = np.mean([outputs[i][0] for i in range(len(outputs))], axis=0)\n",
    "        test_pred = np.mean([outputs[i][1] for i in range(len(outputs))], axis=0)\n",
    "\n",
    "    best_score, best_thresh = f1_smart(Y_val, y_pred)\n",
    "    # best_score, best_thresh = threshold_search(Y_val, y_pred)\n",
    "    print('Optimal F1: {:.4f} at threshold: {:.4f}'.format(best_score, best_thresh))\n",
    "    # threshold = 0.34\n",
    "    pred_test_y = (test_pred > best_thresh).astype(int)\n",
    "\n",
    "sub['prediction'] = pred_test_y\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model | Structure | Dropout | Embedding | Epochs | Fold | replace_punc | maxlen | max_features | batch_size | F1_local | thresh_local | loss_local | F1_online | thresh_online | loss_online | F1_submit | time/epoch(local-online) | notebook\n",
    ":---- | :-------- | :------ | :-- | :----- | :--- | :----- | :----------- | :--------- | :--------- | :----- | :----- | :--------- | :----- | :----- | :------ | :------ | :------ | :------:\n",
    "LstmAtn | Lstm(64)Gru(64)Dense(16) | 0.2/0.1 | mean_gp | 5 | 5 | True | 72 | 95000 | 512 | 0.6864 | 0.3620 | 0.0970 | 0.6874 | 0.3570 | 0.0968 | 0.692 | 90s-240s | qiqc_bp(v1)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(16) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_4(continous) | 95000 | 512 | 0.6889 | 0.3583 | 0.0963 | 0.6874 | 0.3506 | 0.0967 | 0.689 | 90s-242s | qiqc_bp(v16)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_8(cc) | 95000 | 512 | 0.6895 | 0.3949 | 0.0960 | 0.6906 | 0.3630 | 0.0959 | 0.694 | 90s-242s | qiqc_bp(v14)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_4(categorical) | 95000 | 512 | 0.6905 | 0.3708 | 0.0961 | 0.6903 | 0.3764 | 0.0960 | 0.698 | 90s-244s | qiqc_bp(v17)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(16) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_4(categorical) | 95000 | 512 | 0.6887 | 0.3897 | 0.0961 | 0. | 0. | 0. | 0. | 90s-240s | \n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_10(random) | 95000 | 512 | 0.6888 | 0.3916 | 0.0963 | 0.6877 | 0.4023 | 0.0963 | 0.697 | 90s-244s | qiqc_bp(v22)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)seed(26） | 0.2/0.1 | mean_gp | 5 | 5 | False | 70_23(categorical) | 90000 | 512 | 0.6907 | 0.3795 | 0.0958 | 0.6884 | 0.3496 | 0.0961 | 0.694 | 90s-244s | qiqc_bp(v25)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_10(sort) | 95000 | 512 | 0.6903 | 0.3585 | 0.0956 | 0.6901 | 0.3837 | 0.0959 | 0.699 | 90s-244s | qiqc_bp(v27)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_13(sort) | 95000 | 512 | 0.6906 | 0.3558 | 0.0957 | 0.6903 | 0.3772 | 0.0957 | 0.697 | 90s-244s | qiqc_bp(v28)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_12(sort) | 95000 | 512 | 0.6902 | 0.3488 | 0.0959 | 0.6919 | 0.3861 | 0.0956 | 0.697 | 90s-244s | qiqc_bp(v29)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0.6906 | 0.3562 | 0.0957 | 0.6908 | 0.3793 | 0.0955 | 0.700 | 90s-250s | qiqc_bp(v31)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)pool3y | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0.6897 | 0.3707 | 0.0962 | 0. | 0. | 0. | 0. | 94s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)pool3x | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0.6903 | 0.3610 | 0.0957 | 0. | 0. | 0. | 0. | 94s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)FL | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0.6861 | 0.3550 | 5.0649 | 0.6882 | 0.3584 | 5.0502 | 0.694 | 90s-239s/7057s | qiqc_bp(v32)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)FL | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_11(sort) | 90000 | 512 | 0.8424 | 0.3737 | 11.2354 | 0. | 0. | 0. | 0. | 22s-s | qiqc_bp(v) 数据采样\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_11(sort) | 90000 | 512 | 0.8451 | 0.3820 | 0.1983 | 0. | 0. | 0. | 0. | 23s-s | qiqc_bp(v) 数据采样\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_13(sort) | 95000 | 512 | 0.6916 | 0.3811 | 0.0957 | 0.6909 | 0.3766 | 0.0958 | 0.699 | 90s-250s | qiqc_bp(v38)\n",
    "GCDC | Lstm(96)Dense(32) | 0.2/0.1 | mean_gp | 5 | 5 | False | 72_13(sort) | 95000 | 512 | 0.6903 | 0.3502 | 0.0966 | 0. | 0. | 0. | 0. | 90s-244s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp_add_lower | 5 | 5 | False | 72_13(sort) | 95000 | 512 | 0.6925 | 0.3592 | 0.0958 | 0. | 0. | 0. | 0. | 90s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp_add_lower | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0. | 0. | 0. | 0.6911 | 0.3817 | 0.0956 | 0.698 | 90s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/0.1 | mean_gp_smart | 5 | 5 | False | 72_13(sort) | 95000 | 512 | 0.6923 | 0.3358 | 0.0961 | 0. | 0. | 0. | 0. | 90s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)SEED(2019) | 0.2/0.1 | mean_gp_add_lower | 5 | 5 | False | 72_13(sort) | 95000 | 512 | 0.6930 | 0.3515 | 0.0961 | 0.6906 | 0.3532 | 0.0963 | 0.700 | 90s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32)SEED(2019) | 0.2/0.1 | mean_all_add_lower | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0.6919 | 0.3539 | 0.0961 | 0. | 0. | 0. | 0. | 90s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/DC0.1 | mean_gp_add_lower | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0. | 0. | 0. | 0. | 0. | 0. | 0. | 90s-250s | qiqc_bp(v)\n",
    "LstmFAtn | Lstm(64)Gru(64)Dense(32) | 0.2/DC0.2 | mean_gp_add_lower | 5 | 5 | False | 72_11(sort) | 95000 | 512 | 0. | 0. | 0. | 0. | 0. | 0. | 0. | 90s-250s | qiqc_bp(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
